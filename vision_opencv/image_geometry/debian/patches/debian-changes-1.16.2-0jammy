Description: <short summary of the patch>
 TODO: Put a short summary on the line above and replace this paragraph
 with a longer explanation of this change. Complete the meta-information
 with other relevant fields (see below for details). To make it easier, the
 information below has been extracted from the changelog. Adjust it or drop
 it.
 .
 ros-noetic-image-geometry (1.16.2-0jammy) jammy; urgency=high
 .
   * Add fovX and fovY functions in python, cpp, also some typo fixes (#428 <https://github.com/ros-perception/vision_opencv/issues/428>)
   * Contributors: Chris Thierauf, Kenji Brameld
Author: Vincent Rabaud <vincent.rabaud@gmail.com>

---
The information above should follow the Patch Tagging Guidelines, please
checkout http://dep.debian.net/deps/dep3/ to learn about the format. Here
are templates for supplementary fields that you might want to add:

Origin: <vendor|upstream|other>, <url of original patch>
Bug: <url in upstream bugtracker>
Bug-Debian: https://bugs.debian.org/<bugnumber>
Bug-Ubuntu: https://launchpad.net/bugs/<bugnumber>
Forwarded: <no|not-needed|url proving that it has been forwarded>
Reviewed-By: <name and email of someone who approved the patch>
Last-Update: 2024-08-18

--- /dev/null
+++ ros-noetic-image-geometry-1.16.2/CHANGELOG.rst
@@ -0,0 +1,396 @@
+^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
+Changelog for package image_geometry
+^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
+
+1.16.2 (2022-10-03)
+-------------------
+* Add fovX and fovY functions in python, cpp, also some typo fixes (`#428 <https://github.com/ros-perception/vision_opencv/issues/428>`_)
+* Contributors: Chris Thierauf, Kenji Brameld
+
+1.16.1 (2022-09-06)
+-------------------
+
+1.16.0 (2021-11-23)
+-------------------
+* substituted missing sphinx extension (`#417 <https://github.com/ros-perception/vision_opencv/issues/417>`_)
+* Fix rectifyRoi when used with binning and/or ROI (`#378 <https://github.com/ros-perception/vision_opencv/issues/378>`_)
+* Implement unrectifyImage() (`#359 <https://github.com/ros-perception/vision_opencv/issues/359>`_)
+* Add equidistant distortion model (`#358 <https://github.com/ros-perception/vision_opencv/issues/358>`_)
+* Optimize includes (`#354 <https://github.com/ros-perception/vision_opencv/issues/354>`_)
+* Contributors: Markus Vieth, Martin Günther, Paddy
+
+1.15.0 (2020-05-19)
+-------------------
+
+1.14.0 (2020-04-06)
+-------------------
+* Noetic release (`#323 <https://github.com/ros-perception/vision_opencv/issues/323>`_)
+* update CMakeLists.txt for Windows build environment (`#265 <https://github.com/ros-perception/vision_opencv/issues/265>`_)
+* add DLL import/export macros (`#266 <https://github.com/ros-perception/vision_opencv/issues/266>`_)
+* Contributors: Alejandro Hernández Cordero, James Xu
+
+1.13.0 (2018-04-30)
+-------------------
+* Use rosdep OpenCV and not ROS one.
+  We defintely don't need the whole OpenCV.
+  We need to clean the rosdep keys.
+* Contributors: Vincent Rabaud
+
+1.12.8 (2018-04-17)
+-------------------
+* Merge pull request `#189 <https://github.com/ros-perception/vision_opencv/issues/189>`_ from ros2/python3_support_in_test
+  python 3 compatibility in test
+* python 3 compatibility in test
+* fix doc job
+* Contributors: Mikael Arguedas, Vincent Rabaud
+
+1.12.7 (2017-11-12)
+-------------------
+* get shared_ptr from boost or C++11
+* Contributors: Vincent Rabaud
+
+1.12.6 (2017-11-11)
+-------------------
+* missing STL includes
+* Contributors: Mikael Arguedas, Vincent Rabaud
+
+1.12.5 (2017-11-05)
+-------------------
+* Fix compilation issues.
+  Fix suggested by `#173 <https://github.com/ros-perception/vision_opencv/issues/173>`_ comment
+* Make sure to initialize the distorted_image Mat.
+  Otherwise, valgrind throws errors about accessing uninitialized
+  memory.
+  Signed-off-by: Chris Lalancette <clalancette@osrfoundation.org>
+* Remove the last remnants of boost from image_geometry.
+  All of its functionality can be had from std:: in C++11, so
+  use that instead.  This also requires us to add the -std=c++11
+  flag.
+  Signed-off-by: Chris Lalancette <clalancette@osrfoundation.org>
+* Contributors: Chris Lalancette, Vincent Rabaud
+
+1.12.4 (2017-01-29)
+-------------------
+* Import using __future_\_ for python 3 compatibility.
+* Contributors: Hans Gaiser
+
+1.12.3 (2016-12-04)
+-------------------
+
+1.12.2 (2016-09-24)
+-------------------
+* Fix "stdlib.h: No such file or directory" errors in GCC-6
+  Including '-isystem /usr/include' breaks building with GCC-6.
+  See https://gcc.gnu.org/bugzilla/show_bug.cgi?id=70129
+* Merge pull request `#142 <https://github.com/ros-perception/vision_opencv/issues/142>`_ from YuOhara/remap_with_nan_border_value
+  remap with nan border if mat value is float or double
+* remap with nan border if mat value is float or double
+* Contributors: Hodorgasm, Vincent Rabaud, YuOhara
+
+1.12.1 (2016-07-11)
+-------------------
+* Add fullResolution getter to PinholeCameraModel
+* add a missing dependency when building the doc
+* fix sphinx doc path
+* Contributors: Jacob Panikulam, Vincent Rabaud
+
+1.12.0 (2016-03-18)
+-------------------
+* depend on OpenCV3 only
+* Contributors: Vincent Rabaud
+
+1.11.12 (2016-03-10)
+--------------------
+* issue `#117 <https://github.com/ros-perception/vision_opencv/issues/117>`_ pull request `#118 <https://github.com/ros-perception/vision_opencv/issues/118>`_ check all distortion coefficients to see if rectification ought to be done
+* Contributors: Lucas Walter
+
+1.11.11 (2016-01-31)
+--------------------
+* clean up the doc files
+* fix a few warnings in doc jobs
+* Contributors: Vincent Rabaud
+
+1.11.10 (2016-01-16)
+--------------------
+
+1.11.9 (2015-11-29)
+-------------------
+* add a condition if D=None
+* fix compilation warnings
+* Contributors: Vincent Rabaud, YuOhara
+
+1.11.8 (2015-07-15)
+-------------------
+* fixes `#62 <https://github.com/ros-perception/vision_opencv/issues/62>`_, bug in Python rectifyPoint old opencv1 API
+* Simplify some OpenCV3 distinction
+* Contributors: Basheer Subei, Vincent Rabaud
+
+1.11.7 (2014-12-14)
+-------------------
+* Merge pull request `#53 <https://github.com/ros-perception/vision_opencv/issues/53>`_ from carnegieroboticsllc/patch-1
+  Update stereo_camera_model.cpp
+* Updated inline math for reprojecting a single disparity
+* Update stereo_camera_model.cpp
+  Correct slight error in the Q matrix derivation
+* Updated Q matrix to account for cameras with different Fx and Fy values
+* Contributors: Carnegie Robotics LLC, Matt Alvarado, Vincent Rabaud
+
+1.11.6 (2014-11-16)
+-------------------
+* Fixes in image_geometry for Python cv2 API
+* Fixed typo: np -> numpy
+* Added missing tfFrame method to Python PinholeCameraModel.
+* Removed trailing whitespace.
+* Contributors: Daniel Maturana
+
+1.11.5 (2014-09-21)
+-------------------
+* get code to work with OpenCV3
+  actually fixes `#46 <https://github.com/ros-perception/vision_opencv/issues/46>`_ properly
+* Contributors: Vincent Rabaud
+
+1.11.4 (2014-07-27)
+-------------------
+
+1.11.3 (2014-06-08)
+-------------------
+* pinhole_camera_model: fix implicit shared_ptr cast to bool for C++11
+  In C++11 boost::shared_ptr does not provide the implicit bool conversion
+  operator anymore, so make the cast in pinhole_camera_model.h explicit.
+  That does not hurt in older C++ standards and makes compilation with C++11
+  possible.
+* Contributors: Max Schwarz
+
+1.11.2 (2014-04-28)
+-------------------
+
+1.11.1 (2014-04-16)
+-------------------
+
+1.11.0 (2014-02-15)
+-------------------
+* remove OpenCV 1 API
+* fixes `#6 <https://github.com/ros-perception/vision_opencv/issues/6>`_
+* fix OpenCV dependencies
+* Contributors: Vincent Rabaud
+
+1.10.15 (2014-02-07)
+--------------------
+* add assignment operator for StereoCameraModel
+* fixed Python rectifyImage implementation in PinholeCameraModel
+* Added operator= for the PinholeCameraModel.
+  Added the operator= for the PinholeCameraModel. I am not sure if the
+  PinholeCameraModel needs to have a destructor, too. To follow the
+  'rule of three' it should actually have one.
+* Contributors: Tobias Bar, Valsamis Ntouskos, Vincent Rabaud
+
+1.10.14 (2013-11-23 16:17)
+--------------------------
+* Contributors: Vincent Rabaud
+
+1.10.13 (2013-11-23 09:19)
+--------------------------
+* Contributors: Vincent Rabaud
+
+1.10.12 (2013-11-22)
+--------------------
+* "1.10.12"
+* Contributors: Vincent Rabaud
+
+1.10.11 (2013-10-23)
+--------------------
+* Contributors: Vincent Rabaud
+
+1.10.10 (2013-10-19)
+--------------------
+* Contributors: Vincent Rabaud
+
+1.10.9 (2013-10-07)
+-------------------
+* fixes `#23 <https://github.com/ros-perception/vision_opencv/issues/23>`_
+* Contributors: Vincent Rabaud
+
+1.10.8 (2013-09-09)
+-------------------
+* check for CATKIN_ENABLE_TESTING
+* update email  address
+* Contributors: Lukas Bulwahn, Vincent Rabaud
+
+1.10.7 (2013-07-17)
+-------------------
+
+1.10.6 (2013-03-01)
+-------------------
+
+1.10.5 (2013-02-11)
+-------------------
+* Add dependency on generated messages
+  Catkin requires explicit enumeration of dependencies on generated messages.
+  Add this declaration to properly flatten the dependency graph and force Catkin
+  to generate geometry_msgs before compiling image_geometry.
+* Contributors: Adam Hachey
+
+1.10.4 (2013-02-02)
+-------------------
+
+1.10.3 (2013-01-17)
+-------------------
+
+1.10.2 (2013-01-13)
+-------------------
+* fix ticket 4253
+* Contributors: Vincent Rabaud
+
+1.10.1 (2013-01-10)
+-------------------
+
+1.10.0 (2013-01-03)
+-------------------
+
+1.9.15 (2013-01-02)
+-------------------
+
+1.9.14 (2012-12-30)
+-------------------
+* add feature for https://code.ros.org/trac/ros-pkg/ticket/5592
+* CMake cleanups
+* fix a failing test
+* Contributors: Vincent Rabaud
+
+1.9.13 (2012-12-15)
+-------------------
+* use the catkin macros for the setup.py
+* Contributors: Vincent Rabaud
+
+1.9.12 (2012-12-14)
+-------------------
+* buildtool_depend catkin fix
+* Contributors: William Woodall
+
+1.9.11 (2012-12-10)
+-------------------
+* Fixing image_geometry package.xml
+* fix https://code.ros.org/trac/ros-pkg/ticket/5570
+* Contributors: Vincent Rabaud, William Woodall
+
+1.9.10 (2012-10-04)
+-------------------
+
+1.9.9 (2012-10-01)
+------------------
+* fix dependencies
+* Contributors: Vincent Rabaud
+
+1.9.8 (2012-09-30)
+------------------
+* fix some dependencies
+* fix missing Python at install and fix some dependencies
+* Contributors: Vincent Rabaud
+
+1.9.7 (2012-09-28 21:07)
+------------------------
+* add missing stuff
+* make sure we find catkin
+* Contributors: Vincent Rabaud
+
+1.9.6 (2012-09-28 15:17)
+------------------------
+* make all the tests pass
+* comply to the new Catkin API
+* Contributors: Vincent Rabaud
+
+1.9.5 (2012-09-15)
+------------------
+* remove dependencies to the opencv2 ROS package
+* Contributors: Vincent Rabaud
+
+1.9.4 (2012-09-13)
+------------------
+* make sure the include folders are copied to the right place
+* Contributors: Vincent Rabaud
+
+1.9.3 (2012-09-12)
+------------------
+
+1.9.2 (2012-09-07)
+------------------
+* be more compliant to the latest catkin
+* added catkin_project() to cv_bridge, image_geometry, and opencv_tests
+* Contributors: Jonathan Binney, Vincent Rabaud
+
+1.9.1 (2012-08-28 22:06)
+------------------------
+* remove things that were marked as ROS_DEPRECATED
+* Contributors: Vincent Rabaud
+
+1.9.0 (2012-08-28 14:29)
+------------------------
+* catkinized opencv_tests by Jon Binney
+* fix ticket 5449
+* use OpenCV's projectPoints
+* remove the version check, let's trust OpenCV :)
+* revert the removal of opencv2
+* vision_opencv: Export OpenCV flags in manifests for image_geometry, cv_bridge.
+* finally get rid of opencv2 as it is a system dependency now
+* bump REQUIRED version of OpenCV to 2.3.2, which is what's in ros-fuerte-opencv
+* switch rosdep name to opencv2, to refer to ros-fuerte-opencv2
+* Adding a few missing headers so that client code may compile against pinhole camera model.
+* Adding opencv2 to all manifests, so that client packages may
+  not break when using them.
+* baking in opencv debs and attempting a pre-release
+* image_geometry: (Python) Adjust K and P for ROI/binning. Also expose full resolution K and P. Add raw_roi property.
+* image_geometry: Add Tx, Ty getters (Python).
+* image_geometry: Added tf_frame and stamp properties. Only generate undistort maps when rectifyImage is called.
+* image_geometry: Fix for when D is empty (Python).
+* image_geometry: Take all D coefficients, not just the first 4 (Python).
+* image_geometry: Fix rectification in the presence of binning (`#4848 <https://github.com/ros-perception/vision_opencv/issues/4848>`_).
+* image_geometry: Fixed wg-ros-pkg `#5019 <https://github.com/ros-perception/vision_opencv/issues/5019>`_, error updating StereoCameraModel. Removed manifest dependency on cv_bridge.
+* image_geometry: fromCameraInfo() returns bool, true if parameters have changed since last call.
+* image_geometry: Accessors for full-res K, P.
+* image_geometry: Implemented toFullResolution(), toReducedResolution().
+* image_geometry: Implemented reducedResolution().
+* image_geometry: Implemented rectifiedRoi() with caching. Fixed bug that would cause rectification maps to be regenerated every time.
+* image_geometry: Implemented rectifyRoi().
+* image_geometry: Overloads of projection functions that return the output directly instead of through a reference parameter. Implemented unrectifyRoi(). Added fullResolution(), rawRoi().
+* image_geometry: Library-specific exception class.
+* image_geometry: PIMPL pattern for cached data, so I can change in patch releases if necessary. Changed projectPixelTo3dRay() to normalize to z=1.
+* image_geometry (rep0104): Added binning. Partially fixed ROI (not finding rectified ROI yet). Now interpreting distortion_model. Lots of code cleanup.
+* image_geometry (rep0104): Got tests passing again, were issues with D becoming variable-length.
+* image_geometry: Fixed swapped width/height in computing ROI undistort maps. Partially fixes `#4206 <https://github.com/ros-perception/vision_opencv/issues/4206>`_.
+* image_geometry: getDelta functions, getZ and getDisparity in C++ and Python. Docs and tests for them. Changed Python fx() and friends to pull values out of P instead of K.
+* image_geometry: Added C++ getDeltaU and getDeltaV.
+* `#4201 <https://github.com/ros-perception/vision_opencv/issues/4201>`_, implement/doc/test for getDeltaU getDeltaX getDeltaV getDeltaY
+* Added Ubuntu platform tags to manifest
+* `#4083 <https://github.com/ros-perception/vision_opencv/issues/4083>`_, projectPixelTo3dRay implemented
+* image_geometry: Added PinholeCameraModel::stamp() returning the time stamp.
+* image_geometry: Fixed bugs related to ignoring Tx & Ty in projectPixelTo3dRay and unrectifyPoint. Added Tx() and Ty() accessors.
+* image_geometry: Fixed `#4063 <https://github.com/ros-perception/vision_opencv/issues/4063>`_, PinholeCameraModel ignores Tx term in P matrix.
+* image_geometry: Implemented projectDisparityTo3d, `#4019 <https://github.com/ros-perception/vision_opencv/issues/4019>`_.
+* image_geometry: Implemented unrectifyPoint, with unit tests.
+* image_geometry: Fixed bug in rectifyPoint due to cv::undistortPoints not accepting double pt data, `#4053 <https://github.com/ros-perception/vision_opencv/issues/4053>`_.
+* image_geometry: Tweaked manifest.
+* image_geometry: Better manifest description.
+* Removed tfFrame sample
+* image_geometry: Doxygen main page, manifest updates.
+* image_geometry: Doxygen for StereoCameraModel.
+* image_geometry: Made Q calculation match old stereoproc one.
+* image_geometry: Tweaked projectDisparityImageTo3D API for handling missing values.
+* image_geometry: Added method to project disparity image to 3d. Added ConstPtr version of fromCameraInfo in StereoCameraModel.
+* image_geometry: Export linker flags. Fixed bug that could cause rectification maps to not be initialized before use.
+* Fixed path-handling on gtest for CMake 2.6
+* image_geometry: Added missing source file.
+* image_geometry: Added some C++ docs.
+* image_geometry: Minor cleanup of StereoCameraModel, added it to build. Put in copy constructors.
+* image_geometry: Switched pinhole_camera_model to use new C++ OpenCV types and functions.
+* Remove use of deprecated rosbuild macros
+* image_geometry (C++): Unit test for projecting points uv <-> xyz.
+* image_geometry (C++): Implemented more projection functions, added beginnings of the unit tests.
+* trigger rebuild
+* Enable rosdoc.yaml
+* docs
+* image_geometry: Started C++ API. PinholeCameraModel is in theory (untested) able to track state efficiently and rectify images.
+* First stereo test
+* Checkpoint
+* Skeleton of test
+* First cut
+* Contributors: Vincent Rabaud, ethanrublee, gerkey, jamesb, mihelich, vrabaud, wheeler
--- /dev/null
+++ ros-noetic-image-geometry-1.16.2/CMakeLists.txt
@@ -0,0 +1,37 @@
+cmake_minimum_required(VERSION 3.0.2)
+project(image_geometry)
+
+find_package(catkin REQUIRED sensor_msgs)
+find_package(OpenCV REQUIRED)
+
+catkin_package(CATKIN_DEPENDS sensor_msgs
+               DEPENDS OpenCV
+               INCLUDE_DIRS include
+               LIBRARIES ${PROJECT_NAME}
+)
+
+catkin_python_setup()
+
+include_directories(include)
+include_directories(${catkin_INCLUDE_DIRS} ${OpenCV_INCLUDE_DIRS})
+
+# add a library
+add_library(${PROJECT_NAME} src/pinhole_camera_model.cpp src/stereo_camera_model.cpp)
+target_link_libraries(${PROJECT_NAME} ${OpenCV_LIBRARIES})
+add_dependencies(${PROJECT_NAME} ${catkin_EXPORTED_TARGETS})
+
+install(DIRECTORY include/${PROJECT_NAME}/
+        DESTINATION ${CATKIN_PACKAGE_INCLUDE_DESTINATION}/
+)
+
+# install library
+install(TARGETS ${PROJECT_NAME}
+        ARCHIVE DESTINATION ${CATKIN_PACKAGE_LIB_DESTINATION}
+        LIBRARY DESTINATION ${CATKIN_PACKAGE_LIB_DESTINATION}
+        RUNTIME DESTINATION ${CATKIN_GLOBAL_BIN_DESTINATION}
+)
+
+# add tests
+if(CATKIN_ENABLE_TESTING)
+  add_subdirectory(test)
+endif()
--- /dev/null
+++ ros-noetic-image-geometry-1.16.2/doc/conf.py
@@ -0,0 +1,201 @@
+# -*- coding: utf-8 -*-
+#
+# image_geometry documentation build configuration file, created by
+# sphinx-quickstart on Mon Jun  1 14:21:53 2009.
+#
+# This file is execfile()d with the current directory set to its containing dir.
+#
+# Note that not all possible configuration values are present in this
+# autogenerated file.
+#
+# All configuration values have a default; values that are commented out
+# serve to show the default.
+
+import sys, os
+
+# If extensions (or modules to document with autodoc) are in another directory,
+# add these directories to sys.path here. If the directory is relative to the
+# documentation root, use os.path.abspath to make it absolute, like shown here.
+#sys.path.append(os.path.abspath('.'))
+
+# -- General configuration -----------------------------------------------------
+
+# Add any Sphinx extension module names here, as strings. They can be extensions
+# coming with Sphinx (named 'sphinx.ext.*') or your custom ones.
+extensions = ['sphinx.ext.autodoc', 'sphinx.ext.doctest', 'sphinx.ext.intersphinx', 'sphinx.ext.imgmath']
+
+# Add any paths that contain templates here, relative to this directory.
+templates_path = ['_templates']
+
+# The suffix of source filenames.
+source_suffix = '.rst'
+
+# The encoding of source files.
+#source_encoding = 'utf-8'
+
+# The master toctree document.
+master_doc = 'index'
+
+# General information about the project.
+project = u'image_geometry'
+copyright = u'2009, Willow Garage, Inc.'
+
+# The version info for the project you're documenting, acts as replacement for
+# |version| and |release|, also used in various other places throughout the
+# built documents.
+#
+# The short X.Y version.
+version = '0.1'
+# The full version, including alpha/beta/rc tags.
+release = '0.1.0'
+
+# The language for content autogenerated by Sphinx. Refer to documentation
+# for a list of supported languages.
+#language = None
+
+# There are two options for replacing |today|: either, you set today to some
+# non-false value, then it is used:
+#today = ''
+# Else, today_fmt is used as the format for a strftime call.
+#today_fmt = '%B %d, %Y'
+
+# List of documents that shouldn't be included in the build.
+#unused_docs = []
+
+# List of directories, relative to source directory, that shouldn't be searched
+# for source files.
+exclude_trees = ['_build']
+
+# The reST default role (used for this markup: `text`) to use for all documents.
+#default_role = None
+
+# If true, '()' will be appended to :func: etc. cross-reference text.
+#add_function_parentheses = True
+
+# If true, the current module name will be prepended to all description
+# unit titles (such as .. function::).
+#add_module_names = True
+
+# If true, sectionauthor and moduleauthor directives will be shown in the
+# output. They are ignored by default.
+#show_authors = False
+
+# The name of the Pygments (syntax highlighting) style to use.
+pygments_style = 'sphinx'
+
+# A list of ignored prefixes for module index sorting.
+#modindex_common_prefix = []
+
+
+# -- Options for HTML output ---------------------------------------------------
+
+# The theme to use for HTML and HTML Help pages.  Major themes that come with
+# Sphinx are currently 'default' and 'sphinxdoc'.
+html_theme = 'default'
+
+# Theme options are theme-specific and customize the look and feel of a theme
+# further.  For a list of options available for each theme, see the
+# documentation.
+#html_theme_options = {}
+
+# Add any paths that contain custom themes here, relative to this directory.
+#html_theme_path = []
+
+# The name for this set of Sphinx documents.  If None, it defaults to
+# "<project> v<release> documentation".
+#html_title = None
+
+# A shorter title for the navigation bar.  Default is the same as html_title.
+#html_short_title = None
+
+# The name of an image file (relative to this directory) to place at the top
+# of the sidebar.
+#html_logo = None
+
+# The name of an image file (within the static path) to use as favicon of the
+# docs.  This file should be a Windows icon file (.ico) being 16x16 or 32x32
+# pixels large.
+#html_favicon = None
+
+# Add any paths that contain custom static files (such as style sheets) here,
+# relative to this directory. They are copied after the builtin static files,
+# so a file named "default.css" will overwrite the builtin "default.css".
+#html_static_path = ['_static']
+
+# If not '', a 'Last updated on:' timestamp is inserted at every page bottom,
+# using the given strftime format.
+#html_last_updated_fmt = '%b %d, %Y'
+
+# If true, SmartyPants will be used to convert quotes and dashes to
+# typographically correct entities.
+#html_use_smartypants = True
+
+# Custom sidebar templates, maps document names to template names.
+#html_sidebars = {}
+
+# Additional templates that should be rendered to pages, maps page names to
+# template names.
+#html_additional_pages = {}
+
+# If false, no module index is generated.
+#html_use_modindex = True
+
+# If false, no index is generated.
+#html_use_index = True
+
+# If true, the index is split into individual pages for each letter.
+#html_split_index = False
+
+# If true, links to the reST sources are added to the pages.
+#html_show_sourcelink = True
+
+# If true, an OpenSearch description file will be output, and all pages will
+# contain a <link> tag referring to it.  The value of this option must be the
+# base URL from which the finished HTML is served.
+#html_use_opensearch = ''
+
+# If nonempty, this is the file name suffix for HTML files (e.g. ".xhtml").
+#html_file_suffix = ''
+
+# Output file base name for HTML help builder.
+htmlhelp_basename = 'image_geometrydoc'
+
+
+# -- Options for LaTeX output --------------------------------------------------
+
+# The paper size ('letter' or 'a4').
+#latex_paper_size = 'letter'
+
+# The font size ('10pt', '11pt' or '12pt').
+#latex_font_size = '10pt'
+
+# Grouping the document tree into LaTeX files. List of tuples
+# (source start file, target name, title, author, documentclass [howto/manual]).
+latex_documents = [
+  ('index', 'image_geometry.tex', u'stereo\\_utils Documentation',
+   u'James Bowman', 'manual'),
+]
+
+# The name of an image file (relative to this directory) to place at the top of
+# the title page.
+#latex_logo = None
+
+# For "manual" documents, if this is true, then toplevel headings are parts,
+# not chapters.
+#latex_use_parts = False
+
+# Additional stuff for the LaTeX preamble.
+#latex_preamble = ''
+
+# Documents to append as an appendix to all manuals.
+#latex_appendices = []
+
+# If false, no module index is generated.
+#latex_use_modindex = True
+
+# Example configuration for intersphinx: refer to the Python standard library.
+intersphinx_mapping = {
+    'http://docs.python.org/': None,
+    'http://docs.scipy.org/doc/numpy' : None,
+    'http://docs.ros.org/api/tf/html/python/' : None,
+    }
--- /dev/null
+++ ros-noetic-image-geometry-1.16.2/doc/index.rst
@@ -0,0 +1,21 @@
+image_geometry
+==============
+
+image_geometry simplifies interpreting images geometrically using the
+parameters from sensor_msgs/CameraInfo.
+
+.. module:: image_geometry
+
+.. autoclass:: image_geometry.PinholeCameraModel
+      :members: fromCameraInfo, rectifyImage, rectifyPoint, tfFrame, project3dToPixel, projectPixelTo3dRay, distortionCoeffs, intrinsicMatrix, projectionMatrix, rotationMatrix, cx, cy, fx, fy
+
+.. autoclass:: image_geometry.StereoCameraModel
+      :members:
+
+
+Indices and tables
+==================
+
+* :ref:`genindex`
+* :ref:`search`
+
--- /dev/null
+++ ros-noetic-image-geometry-1.16.2/doc/mainpage.dox
@@ -0,0 +1,29 @@
+/**
+\mainpage
+\htmlinclude manifest.html
+
+\b image_geometry contains camera model classes that simplify interpreting
+images geometrically using the calibration parameters from
+sensor_msgs/CameraInfo messages. They may be efficiently updated in your
+image callback:
+
+\code
+image_geometry::PinholeCameraModel model_;
+
+void imageCb(const sensor_msgs::ImageConstPtr& raw_image,
+             const sensor_msgs::CameraInfoConstPtr& cam_info)
+{
+  // Update the camera model (usually a no-op)
+  model_.fromCameraInfo(cam_info);
+
+  // Do processing...
+}
+\endcode
+
+\section codeapi Code API
+
+\b image_geometry contains two classes:
+ - image_geometry::PinholeCameraModel - models a pinhole camera with distortion.
+ - image_geometry::StereoCameraModel - models a stereo pair of pinhole cameras.
+
+*/
--- /dev/null
+++ ros-noetic-image-geometry-1.16.2/include/image_geometry/exports.h
@@ -0,0 +1,18 @@
+#ifndef IMAGE_GEOMETRY_EXPORTS_H
+#define IMAGE_GEOMETRY_EXPORTS_H
+
+#include <ros/macros.h>
+
+// Import/export for windows dll's and visibility for gcc shared libraries.
+
+#ifdef ROS_BUILD_SHARED_LIBS // ros is being built around shared libraries
+  #ifdef image_geometry_EXPORTS // we are building a shared lib/dll
+    #define IMAGE_GEOMETRY_DECL ROS_HELPER_EXPORT
+  #else // we are using shared lib/dll
+    #define IMAGE_GEOMETRY_DECL ROS_HELPER_IMPORT
+  #endif
+#else // ros is being built around static libraries
+  #define IMAGE_GEOMETRY_DECL
+#endif
+
+#endif // IMAGE_GEOMETRY_EXPORTS_H
--- /dev/null
+++ ros-noetic-image-geometry-1.16.2/include/image_geometry/pinhole_camera_model.h
@@ -0,0 +1,365 @@
+#ifndef IMAGE_GEOMETRY_PINHOLE_CAMERA_MODEL_H
+#define IMAGE_GEOMETRY_PINHOLE_CAMERA_MODEL_H
+
+#include <sensor_msgs/CameraInfo.h>
+#include <opencv2/core/mat.hpp>
+#include <opencv2/imgproc/imgproc.hpp>
+#include <stdexcept>
+#include <string>
+#include <math.h>
+#include "exports.h"
+
+namespace image_geometry {
+
+class Exception : public std::runtime_error
+{
+public:
+  Exception(const std::string& description) : std::runtime_error(description) {}
+};
+
+/**
+ * \brief Simplifies interpreting images geometrically using the parameters from
+ * sensor_msgs/CameraInfo.
+ */
+class IMAGE_GEOMETRY_DECL PinholeCameraModel
+{
+public:
+
+  PinholeCameraModel();
+
+  PinholeCameraModel(const PinholeCameraModel& other);
+
+  PinholeCameraModel& operator=(const PinholeCameraModel& other);
+
+  /**
+   * \brief Set the camera parameters from the sensor_msgs/CameraInfo message.
+   */
+  bool fromCameraInfo(const sensor_msgs::CameraInfo& msg);
+
+  /**
+   * \brief Set the camera parameters from the sensor_msgs/CameraInfo message.
+   */
+  bool fromCameraInfo(const sensor_msgs::CameraInfoConstPtr& msg);
+
+  /**
+   * \brief Get the name of the camera coordinate frame in tf.
+   */
+  std::string tfFrame() const;
+
+  /**
+   * \brief Get the time stamp associated with this camera model.
+   */
+  ros::Time stamp() const;
+
+  /**
+   * \brief The resolution at which the camera was calibrated.
+   *
+   * The maximum resolution at which the camera can be used with the current
+   * calibration; normally this is the same as the imager resolution.
+   */
+  cv::Size fullResolution() const;
+
+  /**
+   * \brief The resolution of the current rectified image.
+   *
+   * The size of the rectified image associated with the latest CameraInfo, as
+   * reduced by binning/ROI and affected by distortion. If binning and ROI are
+   * not in use, this is the same as fullResolution().
+   */
+  cv::Size reducedResolution() const;
+
+  cv::Point2d toFullResolution(const cv::Point2d& uv_reduced) const;
+
+  cv::Rect toFullResolution(const cv::Rect& roi_reduced) const;
+
+  cv::Point2d toReducedResolution(const cv::Point2d& uv_full) const;
+
+  cv::Rect toReducedResolution(const cv::Rect& roi_full) const;
+
+  /**
+   * \brief The current raw ROI, as used for capture by the camera driver.
+   */
+  cv::Rect rawRoi() const;
+
+  /**
+   * \brief The current rectified ROI, which best fits the raw ROI.
+   */
+  cv::Rect rectifiedRoi() const;
+
+  /**
+   * \brief Project a 3d point to rectified pixel coordinates.
+   *
+   * This is the inverse of projectPixelTo3dRay().
+   *
+   * \param xyz 3d point in the camera coordinate frame
+   * \return (u,v) in rectified pixel coordinates
+   */
+  cv::Point2d project3dToPixel(const cv::Point3d& xyz) const;
+
+  /**
+   * \brief Project a rectified pixel to a 3d ray.
+   *
+   * Returns the unit vector in the camera coordinate frame in the direction of rectified
+   * pixel (u,v) in the image plane. This is the inverse of project3dToPixel().
+   *
+   * In 1.4.x, the vector has z = 1.0. Previously, this function returned a unit vector.
+   *
+   * \param uv_rect Rectified pixel coordinates
+   * \return 3d ray passing through (u,v)
+   */
+  cv::Point3d projectPixelTo3dRay(const cv::Point2d& uv_rect) const;
+  cv::Point3d projectPixelTo3dRay(const cv::Point2d& uv_rect, const cv::Matx34d& P) const;
+
+  /**
+   * \brief Rectify a raw camera image.
+   */
+  void rectifyImage(const cv::Mat& raw, cv::Mat& rectified,
+                    int interpolation = cv::INTER_LINEAR) const;
+
+  /**
+   * \brief Apply camera distortion to a rectified image.
+   */
+  void unrectifyImage(const cv::Mat& rectified, cv::Mat& raw,
+                      int interpolation = cv::INTER_LINEAR) const;
+
+  /**
+   * \brief Compute the rectified image coordinates of a pixel in the raw image.
+   */
+  cv::Point2d rectifyPoint(const cv::Point2d& uv_raw) const;
+  cv::Point2d rectifyPoint(const cv::Point2d& uv_raw, const cv::Matx33d& K, const cv::Matx34d& P) const;
+
+  /**
+   * \brief Compute the raw image coordinates of a pixel in the rectified image.
+   */
+  cv::Point2d unrectifyPoint(const cv::Point2d& uv_rect) const;
+  cv::Point2d unrectifyPoint(const cv::Point2d& uv_rect, const cv::Matx33d& K, const cv::Matx34d& P) const;
+
+  /**
+   * \brief Compute the rectified ROI best fitting a raw ROI.
+   */
+  cv::Rect rectifyRoi(const cv::Rect& roi_raw) const;
+
+  /**
+   * \brief Compute the raw ROI best fitting a rectified ROI.
+   */
+  cv::Rect unrectifyRoi(const cv::Rect& roi_rect) const;
+
+  /**
+   * \brief Returns the camera info message held internally
+   */
+  const sensor_msgs::CameraInfo& cameraInfo() const;
+
+  /**
+   * \brief Returns the original camera matrix.
+   */
+  const cv::Matx33d& intrinsicMatrix() const;
+
+  /**
+   * \brief Returns the distortion coefficients.
+   */
+  const cv::Mat_<double>& distortionCoeffs() const;
+
+  /**
+   * \brief Returns the rotation matrix.
+   */
+  const cv::Matx33d& rotationMatrix() const;
+
+  /**
+   * \brief Returns the projection matrix.
+   */
+  const cv::Matx34d& projectionMatrix() const;
+
+  /**
+   * \brief Returns the original camera matrix for full resolution.
+   */
+  const cv::Matx33d& fullIntrinsicMatrix() const;
+
+  /**
+   * \brief Returns the projection matrix for full resolution.
+   */
+  const cv::Matx34d& fullProjectionMatrix() const;
+
+  /**
+   * \brief Returns the focal length (pixels) in x direction of the rectified image.
+   */
+  double fx() const;
+
+  /**
+   * \brief Returns the focal length (pixels) in y direction of the rectified image.
+   */
+  double fy() const;
+
+  /**
+   * \brief Returns the x coordinate of the optical center.
+   */
+  double cx() const;
+
+  /**
+   * \brief Returns the y coordinate of the optical center.
+   */
+  double cy() const;
+
+  /**
+   * \brief Returns the x-translation term of the projection matrix.
+   */
+  double Tx() const;
+
+  /**
+   * \brief Returns the y-translation term of the projection matrix.
+   */
+  double Ty() const;
+
+  /**
+   * \brief Returns the horizontal field of view in radians.
+   */
+  double fovX() const;
+
+  /**
+   * \brief Returns the vertical field of view in radians.
+   */
+  double fovY() const;
+
+  /**
+   * \brief Returns the number of columns in each bin.
+   */
+  uint32_t binningX() const;
+
+  /**
+   * \brief Returns the number of rows in each bin.
+   */
+  uint32_t binningY() const;
+
+  /**
+   * \brief Compute delta u, given Z and delta X in Cartesian space.
+   *
+   * For given Z, this is the inverse of getDeltaX().
+   *
+   * \param deltaX Delta X, in Cartesian space
+   * \param Z      Z (depth), in Cartesian space
+   */
+  double getDeltaU(double deltaX, double Z) const;
+
+  /**
+   * \brief Compute delta v, given Z and delta Y in Cartesian space.
+   *
+   * For given Z, this is the inverse of getDeltaY().
+   *
+   * \param deltaY Delta Y, in Cartesian space
+   * \param Z      Z (depth), in Cartesian space
+   */
+  double getDeltaV(double deltaY, double Z) const;
+
+  /**
+   * \brief Compute delta X, given Z in Cartesian space and delta u in pixels.
+   *
+   * For given Z, this is the inverse of getDeltaU().
+   *
+   * \param deltaU Delta u, in pixels
+   * \param Z      Z (depth), in Cartesian space
+   */
+  double getDeltaX(double deltaU, double Z) const;
+
+  /**
+   * \brief Compute delta Y, given Z in Cartesian space and delta v in pixels.
+   *
+   * For given Z, this is the inverse of getDeltaV().
+   *
+   * \param deltaV Delta v, in pixels
+   * \param Z      Z (depth), in Cartesian space
+   */
+  double getDeltaY(double deltaV, double Z) const;
+
+  /**
+   * \brief Returns true if the camera has been initialized
+   */
+  bool initialized() const { return (bool)cache_; }
+
+protected:
+  sensor_msgs::CameraInfo cam_info_;
+  cv::Mat_<double> D_;           // Unaffected by binning, ROI
+  cv::Matx33d R_;           // Unaffected by binning, ROI
+  cv::Matx33d K_;           // Describe current image (includes binning, ROI)
+  cv::Matx34d P_;           // Describe current image (includes binning, ROI)
+  cv::Matx33d K_full_; // Describe full-res image, needed for full maps
+  cv::Matx34d P_full_; // Describe full-res image, needed for full maps
+
+  // Use PIMPL here so we can change internals in patch updates if needed
+  struct Cache;
+#ifdef BOOST_SHARED_PTR_HPP_INCLUDED
+  boost::shared_ptr<Cache> cache_; // Holds cached data for internal use
+#else
+  std::shared_ptr<Cache> cache_; // Holds cached data for internal use
+#endif
+
+  void initRectificationMaps() const;
+  void initUnrectificationMaps() const;
+
+  friend class StereoCameraModel;
+};
+
+
+/* Trivial inline functions */
+inline std::string PinholeCameraModel::tfFrame() const
+{
+  assert( initialized() );
+  return cam_info_.header.frame_id;
+}
+
+inline ros::Time PinholeCameraModel::stamp() const
+{
+  assert( initialized() );
+  return cam_info_.header.stamp;
+}
+
+inline const sensor_msgs::CameraInfo& PinholeCameraModel::cameraInfo() const  { return cam_info_; }
+inline const cv::Matx33d& PinholeCameraModel::intrinsicMatrix() const  { return K_; }
+inline const cv::Mat_<double>& PinholeCameraModel::distortionCoeffs() const { return D_; }
+inline const cv::Matx33d& PinholeCameraModel::rotationMatrix() const   { return R_; }
+inline const cv::Matx34d& PinholeCameraModel::projectionMatrix() const { return P_; }
+inline const cv::Matx33d& PinholeCameraModel::fullIntrinsicMatrix() const  { return K_full_; }
+inline const cv::Matx34d& PinholeCameraModel::fullProjectionMatrix() const { return P_full_; }
+
+inline double PinholeCameraModel::fx() const { return P_(0,0); }
+inline double PinholeCameraModel::fy() const { return P_(1,1); }
+inline double PinholeCameraModel::cx() const { return P_(0,2); }
+inline double PinholeCameraModel::cy() const { return P_(1,2); }
+inline double PinholeCameraModel::Tx() const { return P_(0,3); }
+inline double PinholeCameraModel::Ty() const { return P_(1,3); }
+
+inline double PinholeCameraModel::fovX() const {
+        return 2 * atan(rawRoi().width / (2 * fx()));
+}
+inline double PinholeCameraModel::fovY() const {
+        return 2 * atan(rawRoi().height / (2 * fy()));
+}
+
+inline uint32_t PinholeCameraModel::binningX() const { return cam_info_.binning_x; }
+inline uint32_t PinholeCameraModel::binningY() const { return cam_info_.binning_y; }
+
+inline double PinholeCameraModel::getDeltaU(double deltaX, double Z) const
+{
+  assert( initialized() );
+  return fx() * deltaX / Z;
+}
+
+inline double PinholeCameraModel::getDeltaV(double deltaY, double Z) const
+{
+  assert( initialized() );
+  return fy() * deltaY / Z;
+}
+
+inline double PinholeCameraModel::getDeltaX(double deltaU, double Z) const
+{
+  assert( initialized() );
+  return Z * deltaU / fx();
+}
+
+inline double PinholeCameraModel::getDeltaY(double deltaV, double Z) const
+{
+  assert( initialized() );
+  return Z * deltaV / fy();
+}
+
+} //namespace image_geometry
+
+#endif
--- /dev/null
+++ ros-noetic-image-geometry-1.16.2/include/image_geometry/stereo_camera_model.h
@@ -0,0 +1,131 @@
+#ifndef IMAGE_GEOMETRY_STEREO_CAMERA_MODEL_H
+#define IMAGE_GEOMETRY_STEREO_CAMERA_MODEL_H
+
+#include "image_geometry/pinhole_camera_model.h"
+#include "exports.h"
+
+namespace image_geometry {
+
+/**
+ * \brief Simplifies interpreting stereo image pairs geometrically using the
+ * parameters from the left and right sensor_msgs/CameraInfo.
+ */
+class IMAGE_GEOMETRY_DECL StereoCameraModel
+{
+public:
+  StereoCameraModel();
+
+  StereoCameraModel(const StereoCameraModel& other);
+
+  StereoCameraModel& operator=(const StereoCameraModel& other);
+
+  /**
+   * \brief Set the camera parameters from the sensor_msgs/CameraInfo messages.
+   */
+  bool fromCameraInfo(const sensor_msgs::CameraInfo& left,
+                      const sensor_msgs::CameraInfo& right);
+
+  /**
+   * \brief Set the camera parameters from the sensor_msgs/CameraInfo messages.
+   */
+  bool fromCameraInfo(const sensor_msgs::CameraInfoConstPtr& left,
+                      const sensor_msgs::CameraInfoConstPtr& right);
+
+  /**
+   * \brief Get the left monocular camera model.
+   */
+  const PinholeCameraModel& left() const;
+
+  /**
+   * \brief Get the right monocular camera model.
+   */
+  const PinholeCameraModel& right() const;
+
+  /**
+   * \brief Get the name of the camera coordinate frame in tf.
+   *
+   * For stereo cameras, both the left and right CameraInfo should be in the left
+   * optical frame.
+   */
+  std::string tfFrame() const;
+
+  /**
+   * \brief Project a rectified pixel with disparity to a 3d point.
+   */
+  void projectDisparityTo3d(const cv::Point2d& left_uv_rect, float disparity, cv::Point3d& xyz) const;
+
+  /**
+   * \brief Project a disparity image to a 3d point cloud.
+   *
+   * If handleMissingValues = true, all points with minimal disparity (outliers) have
+   * Z set to MISSING_Z (currently 10000.0).
+   */
+  void projectDisparityImageTo3d(const cv::Mat& disparity, cv::Mat& point_cloud,
+                                 bool handleMissingValues = false) const;
+  static const double MISSING_Z;
+  
+  /**
+   * \brief Returns the disparity reprojection matrix.
+   */
+  const cv::Matx44d& reprojectionMatrix() const;
+
+  /**
+   * \brief Returns the horizontal baseline in world coordinates.
+   */
+  double baseline() const;
+
+  /**
+   * \brief Returns the depth at which a point is observed with a given disparity.
+   *
+   * This is the inverse of getDisparity().
+   */
+  double getZ(double disparity) const;
+
+  /**
+   * \brief Returns the disparity observed for a point at depth Z.
+   *
+   * This is the inverse of getZ().
+   */
+  double getDisparity(double Z) const;
+
+  /**
+   * \brief Returns true if the camera has been initialized
+   */
+  bool initialized() const { return left_.initialized() && right_.initialized(); }
+protected:
+  PinholeCameraModel left_, right_;
+  cv::Matx44d Q_;
+
+  void updateQ();
+};
+
+
+/* Trivial inline functions */
+inline const PinholeCameraModel& StereoCameraModel::left() const  { return left_; }
+inline const PinholeCameraModel& StereoCameraModel::right() const { return right_; }
+
+inline std::string StereoCameraModel::tfFrame() const { return left_.tfFrame(); }
+
+inline const cv::Matx44d& StereoCameraModel::reprojectionMatrix() const { return Q_; }
+
+inline double StereoCameraModel::baseline() const
+{
+  /// @todo Currently assuming horizontal baseline
+  return -right_.Tx() / right_.fx();
+}
+
+inline double StereoCameraModel::getZ(double disparity) const
+{
+  assert( initialized() );
+  return -right_.Tx() / (disparity - (left().cx() - right().cx()));
+}
+
+inline double StereoCameraModel::getDisparity(double Z) const
+{
+  assert( initialized() );
+  return -right_.Tx() / Z + (left().cx() - right().cx()); ;
+}
+
+} //namespace image_geometry
+
+#endif
--- /dev/null
+++ ros-noetic-image-geometry-1.16.2/package.xml
@@ -0,0 +1,30 @@
+<package format="2">
+  <name>image_geometry</name>
+  <version>1.16.2</version>
+  <description>
+    `image_geometry` contains C++ and Python libraries for interpreting images
+    geometrically. It interfaces the calibration parameters in sensor_msgs/CameraInfo
+    messages with OpenCV functions such as image rectification, much as cv_bridge
+    interfaces ROS sensor_msgs/Image with OpenCV data types.
+  </description>
+  <author>Patrick Mihelich</author>
+  <maintainer email="vincent.rabaud@gmail.com">Vincent Rabaud</maintainer>
+  <license>BSD</license>
+  <url>http://www.ros.org/wiki/image_geometry</url>
+
+  <export>
+    <rosdoc config="rosdoc.yaml" />
+  </export>
+
+  <buildtool_depend>catkin</buildtool_depend>
+
+  <build_depend>libopencv-dev</build_depend>
+  <build_depend>sensor_msgs</build_depend>
+
+  <exec_depend>libopencv-dev</exec_depend>
+  <build_export_depend>libopencv-dev</build_export_depend>
+  <build_export_depend>sensor_msgs</build_export_depend>
+
+  <doc_depend>dvipng</doc_depend>
+  <doc_depend>texlive-latex-extra</doc_depend>
+</package>
--- /dev/null
+++ ros-noetic-image-geometry-1.16.2/rosdoc.yaml
@@ -0,0 +1,8 @@
+ - builder: sphinx
+   name: Python API
+   output_dir: python
+   sphinx_root_dir: doc
+ - builder: doxygen
+   name: C++ API
+   output_dir: c++
+   file_patterns: '*.c *.cpp *.h *.cc *.hh *.dox'
--- /dev/null
+++ ros-noetic-image-geometry-1.16.2/setup.py
@@ -0,0 +1,10 @@
+#!/usr/bin/env python
+from setuptools import setup
+from catkin_pkg.python_setup import generate_distutils_setup
+
+d = generate_distutils_setup()
+
+d['packages'] = ['image_geometry']
+d['package_dir'] = {'' : 'src'}
+
+setup(**d)
--- /dev/null
+++ ros-noetic-image-geometry-1.16.2/src/image_geometry/__init__.py
@@ -0,0 +1,2 @@
+from __future__ import absolute_import
+from .cameramodels import PinholeCameraModel, StereoCameraModel
--- /dev/null
+++ ros-noetic-image-geometry-1.16.2/src/image_geometry/cameramodels.py
@@ -0,0 +1,388 @@
+import cv2
+import math
+import copy
+import numpy
+
+def mkmat(rows, cols, L):
+    mat = numpy.matrix(L, dtype='float64')
+    mat.resize((rows,cols))
+    return mat
+
+class PinholeCameraModel:
+
+    """
+    A pinhole camera is an idealized monocular camera.
+    """
+
+    def __init__(self):
+        self.K = None
+        self.D = None
+        self.R = None
+        self.P = None
+        self.full_K = None
+        self.full_P = None
+        self.width = None
+        self.height = None
+        self.binning_x = None
+        self.binning_y = None
+        self.raw_roi = None
+        self.tf_frame = None
+        self.stamp = None
+
+    def fromCameraInfo(self, msg):
+        """
+        :param msg: camera parameters
+        :type msg:  sensor_msgs.msg.CameraInfo
+
+        Set the camera parameters from the :class:`sensor_msgs.msg.CameraInfo` message.
+        """
+        self.K = mkmat(3, 3, msg.K)
+        if msg.D:
+            self.D = mkmat(len(msg.D), 1, msg.D)
+        else:
+            self.D = None
+        self.R = mkmat(3, 3, msg.R)
+        self.P = mkmat(3, 4, msg.P)
+        self.full_K = mkmat(3, 3, msg.K)
+        self.full_P = mkmat(3, 4, msg.P)
+        self.width = msg.width
+        self.height = msg.height
+        self.binning_x = max(1, msg.binning_x)
+        self.binning_y = max(1, msg.binning_y)
+        self.resolution = (msg.width, msg.height)
+
+        self.raw_roi = copy.copy(msg.roi)
+        # ROI all zeros is considered the same as full resolution
+        if (self.raw_roi.x_offset == 0 and self.raw_roi.y_offset == 0 and
+            self.raw_roi.width == 0 and self.raw_roi.height == 0):
+            self.raw_roi.width = self.width
+            self.raw_roi.height = self.height
+        self.tf_frame = msg.header.frame_id
+        self.stamp = msg.header.stamp
+
+        # Adjust K and P for binning and ROI
+        self.K[0,0] /= self.binning_x
+        self.K[1,1] /= self.binning_y
+        self.K[0,2] = (self.K[0,2] - self.raw_roi.x_offset) / self.binning_x
+        self.K[1,2] = (self.K[1,2] - self.raw_roi.y_offset) / self.binning_y
+        self.P[0,0] /= self.binning_x
+        self.P[1,1] /= self.binning_y
+        self.P[0,2] = (self.P[0,2] - self.raw_roi.x_offset) / self.binning_x
+        self.P[1,2] = (self.P[1,2] - self.raw_roi.y_offset) / self.binning_y
+
+    def rectifyImage(self, raw, rectified):
+        """
+        :param raw:       input image
+        :type raw:        :class:`CvMat` or :class:`IplImage`
+        :param rectified: rectified output image
+        :type rectified:  :class:`CvMat` or :class:`IplImage`
+
+        Applies the rectification specified by camera parameters :math:`K` and and :math:`D` to image `raw` and writes the resulting image `rectified`.
+        """
+
+        self.mapx = numpy.ndarray(shape=(self.height, self.width, 1),
+                           dtype='float32')
+        self.mapy = numpy.ndarray(shape=(self.height, self.width, 1),
+                           dtype='float32')
+        cv2.initUndistortRectifyMap(self.K, self.D, self.R, self.P,
+                (self.width, self.height), cv2.CV_32FC1, self.mapx, self.mapy)
+        cv2.remap(raw, self.mapx, self.mapy, cv2.INTER_CUBIC, rectified)
+
+    def rectifyPoint(self, uv_raw):
+        """
+        :param uv_raw:    pixel coordinates
+        :type uv_raw:     (u, v)
+
+        Applies the rectification specified by camera parameters
+        :math:`K` and and :math:`D` to point (u, v) and returns the
+        pixel coordinates of the rectified point.
+        """
+
+        src = mkmat(1, 2, list(uv_raw))
+        src.resize((1,1,2))
+        dst = cv2.undistortPoints(src, self.K, self.D, R=self.R, P=self.P)
+        return dst[0,0]
+
+    def project3dToPixel(self, point):
+        """
+        :param point:     3D point
+        :type point:      (x, y, z)
+
+        Returns the rectified pixel coordinates (u, v) of the 3D point,
+        using the camera :math:`P` matrix.
+        This is the inverse of :math:`projectPixelTo3dRay`.
+        """
+        src = mkmat(4, 1, [point[0], point[1], point[2], 1.0])
+        dst = self.P * src
+        x = dst[0,0]
+        y = dst[1,0]
+        w = dst[2,0]
+        if w != 0:
+            return (x / w, y / w)
+        else:
+            return (float('nan'), float('nan'))
+
+    def projectPixelTo3dRay(self, uv):
+        """
+        :param uv:        rectified pixel coordinates
+        :type uv:         (u, v)
+
+        Returns the unit vector which passes from the camera center to through rectified pixel (u, v),
+        using the camera :math:`P` matrix.
+        This is the inverse of :math:`project3dToPixel`.
+        """
+        x = (uv[0] - self.cx()) / self.fx()
+        y = (uv[1] - self.cy()) / self.fy()
+        norm = math.sqrt(x*x + y*y + 1)
+        x /= norm
+        y /= norm
+        z = 1.0 / norm
+        return (x, y, z)
+
+    def getDeltaU(self, deltaX, Z):
+        """
+        :param deltaX:          delta X, in cartesian space
+        :type deltaX:           float
+        :param Z:               Z, in cartesian space
+        :type Z:                float
+        :rtype:                 float
+
+        Compute delta u, given Z and delta X in Cartesian space.
+        For given Z, this is the inverse of :math:`getDeltaX`.
+        """
+        if Z == 0:
+            return float('inf')
+        else:
+            return self.fx() * deltaX / Z
+
+    def getDeltaV(self, deltaY, Z):
+        """
+        :param deltaY:          delta Y, in cartesian space
+        :type deltaY:           float
+        :param Z:               Z, in cartesian space
+        :type Z:                float
+        :rtype:                 float
+
+        Compute delta v, given Z and delta Y in Cartesian space.
+        For given Z, this is the inverse of :math:`getDeltaY`.
+        """
+        if Z == 0:
+            return float('inf')
+        else:
+            return self.fy() * deltaY / Z
+
+    def getDeltaX(self, deltaU, Z):
+        """
+        :param deltaU:          delta u in pixels
+        :type deltaU:           float
+        :param Z:               Z, in cartesian space
+        :type Z:                float
+        :rtype:                 float
+
+        Compute delta X, given Z in cartesian space and delta u in pixels.
+        For given Z, this is the inverse of :math:`getDeltaU`.
+        """
+        return Z * deltaU / self.fx()
+
+    def getDeltaY(self, deltaV, Z):
+        """
+        :param deltaV:          delta v in pixels
+        :type deltaV:           float
+        :param Z:               Z, in cartesian space
+        :type Z:                float
+        :rtype:                 float
+
+        Compute delta Y, given Z in cartesian space and delta v in pixels.
+        For given Z, this is the inverse of :math:`getDeltaV`.
+        """
+        return Z * deltaV / self.fy()
+
+    def fullResolution(self):
+        """Returns the full resolution of the camera"""
+        return self.resolution
+
+    def intrinsicMatrix(self):
+        """ Returns :math:`K`, also called camera_matrix in cv docs """
+        return self.K
+
+    def distortionCoeffs(self):
+        """ Returns :math:`D` """
+        return self.D
+
+    def rotationMatrix(self):
+        """ Returns :math:`R` """
+        return self.R
+
+    def projectionMatrix(self):
+        """ Returns :math:`P` """
+        return self.P
+
+    def fullIntrinsicMatrix(self):
+        """ Return the original camera matrix for full resolution """
+        return self.full_K
+
+    def fullProjectionMatrix(self):
+        """ Return the projection matrix for full resolution """
+        return self.full_P
+
+    def cx(self):
+        """ Returns x center """
+        return self.P[0,2]
+
+    def cy(self):
+        """ Returns y center """
+        return self.P[1,2]
+
+    def fx(self):
+        """ Returns x focal length """
+        return self.P[0,0]
+
+    def fy(self):
+        """ Returns y focal length """
+        return self.P[1,1]
+
+    def Tx(self):
+        """ Return the x-translation term of the projection matrix """
+        return self.P[0,3]
+
+    def Ty(self):
+        """ Return the y-translation term of the projection matrix """
+        return self.P[1,3]
+
+    def fovX(self):
+        """ Returns the horizontal field of view in radians.
+            Horizontal FoV = 2 * arctan((width) / (2 * Horizontal Focal Length) )
+        """
+        return 2 * math.atan(self.width / (2 * self.fx()))
+
+    def fovY(self):
+        """ Returns the vertical field of view in radians.
+            Vertical FoV = 2 * arctan((height) / (2 * Vertical Focal Length) )
+        """
+        return 2 * math.atan(self.height / (2 * self.fy()))
+
+    def tfFrame(self):
+        """ Returns the tf frame name - a string - of the camera.
+        This is the frame of the :class:`sensor_msgs.msg.CameraInfo` message.
+        """
+        return self.tf_frame
+
+class StereoCameraModel:
+    """
+    An idealized stereo camera.
+    """
+    def __init__(self):
+        self.left = PinholeCameraModel()
+        self.right = PinholeCameraModel()
+
+    def fromCameraInfo(self, left_msg, right_msg):
+        """
+        :param left_msg: left camera parameters
+        :type left_msg:  sensor_msgs.msg.CameraInfo
+        :param right_msg: right camera parameters
+        :type right_msg:  sensor_msgs.msg.CameraInfo
+
+        Set the camera parameters from the :class:`sensor_msgs.msg.CameraInfo` messages.
+        """
+        self.left.fromCameraInfo(left_msg)
+        self.right.fromCameraInfo(right_msg)
+
+        # [ Fx, 0,  Cx,  Fx*-Tx ]
+        # [ 0,  Fy, Cy,  0      ]
+        # [ 0,  0,  1,   0      ]
+
+        assert self.right.P is not None
+        fx = self.right.P[0, 0]
+        cx = self.right.P[0, 2]
+        cy = self.right.P[1, 2]
+        tx = -self.right.P[0, 3] / fx
+
+        # Q is:
+        #    [ 1, 0,  0, -Clx ]
+        #    [ 0, 1,  0, -Cy ]
+        #    [ 0, 0,  0,  Fx ]
+        #    [ 0, 0, 1 / Tx, (Crx-Clx)/Tx ]
+
+        self.Q = numpy.zeros((4, 4), dtype='float64')
+        self.Q[0, 0] = 1.0
+        self.Q[0, 3] = -cx
+        self.Q[1, 1] = 1.0
+        self.Q[1, 3] = -cy
+        self.Q[2, 3] = fx
+        self.Q[3, 2] = 1 / tx
+
+    def tfFrame(self):
+        """
+        Returns the tf frame name - a string - of the 3d points.  This is
+        the frame of the :class:`sensor_msgs.msg.CameraInfo` message.  It
+        may be used as a source frame in :class:`tf.TransformListener`.
+        """
+
+        return self.left.tfFrame()
+
+    def project3dToPixel(self, point):
+        """
+        :param point:     3D point
+        :type point:      (x, y, z)
+
+        Returns the rectified pixel coordinates (u, v) of the 3D point, for each camera, as ((u_left, v_left), (u_right, v_right))
+        using the cameras' :math:`P` matrices.
+        This is the inverse of :math:`projectPixelTo3d`.
+        """
+        l = self.left.project3dToPixel(point)
+        r = self.right.project3dToPixel(point)
+        return (l, r)
+
+    def projectPixelTo3d(self, left_uv, disparity):
+        """
+        :param left_uv:        rectified pixel coordinates
+        :type left_uv:         (u, v)
+        :param disparity:        disparity, in pixels
+        :type disparity:         float
+
+        Returns the 3D point (x, y, z) for the given pixel position,
+        using the cameras' :math:`P` matrices.
+        This is the inverse of :math:`project3dToPixel`.
+
+        Note that a disparity of zero implies that the 3D point is at infinity.
+        """
+        src = mkmat(4, 1, [left_uv[0], left_uv[1], disparity, 1.0])
+        dst = self.Q * src
+        x = dst[0, 0]
+        y = dst[1, 0]
+        z = dst[2, 0]
+        w = dst[3, 0]
+        if w != 0:
+            return (x / w, y / w, z / w)
+        else:
+            return (0.0, 0.0, 0.0)
+
+    def getZ(self, disparity):
+        """
+        :param disparity:        disparity, in pixels
+        :type disparity:         float
+
+        Returns the depth at which a point is observed with a given disparity.
+        This is the inverse of :math:`getDisparity`.
+
+        Note that a disparity of zero implies Z is infinite.
+        """
+        if disparity == 0:
+            return float('inf')
+        assert self.right.P is not None
+        Tx = -self.right.P[0, 3]
+        return Tx / disparity
+
+    def getDisparity(self, Z):
+        """
+        :param Z:          Z (depth), in cartesian space
+        :type Z:           float
+
+        Returns the disparity observed for a point at depth Z.
+        This is the inverse of :math:`getZ`.
+        """
+        if Z == 0:
+            return float('inf')
+        assert self.right.P is not None
+        Tx = -self.right.P[0, 3]
+        return Tx / Z
--- /dev/null
+++ ros-noetic-image-geometry-1.16.2/src/pinhole_camera_model.cpp
@@ -0,0 +1,661 @@
+#include "image_geometry/pinhole_camera_model.h"
+#include <sensor_msgs/distortion_models.h>
+#include <opencv2/calib3d/calib3d.hpp>
+#ifdef BOOST_SHARED_PTR_HPP_INCLUDED
+#include <boost/make_shared.hpp>
+#endif
+
+namespace image_geometry {
+
+enum DistortionState { NONE, CALIBRATED, UNKNOWN };
+enum DistortionModel { EQUIDISTANT, PLUMB_BOB_OR_RATIONAL_POLYNOMIAL, UNKNOWN_MODEL };
+
+struct PinholeCameraModel::Cache
+{
+  DistortionState distortion_state;
+  DistortionModel distortion_model;
+
+  cv::Mat_<double> K_binned, P_binned; // Binning applied, but not cropping
+
+  mutable bool full_maps_dirty;
+  mutable cv::Mat full_map1, full_map2;
+
+  mutable bool reduced_maps_dirty;
+  mutable cv::Mat reduced_map1, reduced_map2;
+
+  mutable bool unrectify_full_maps_dirty;
+  mutable cv::Mat unrectify_full_map1, unrectify_full_map2;
+
+  mutable bool unrectify_reduced_maps_dirty;
+  mutable cv::Mat unrectify_reduced_map1, unrectify_reduced_map2;
+
+  mutable bool rectified_roi_dirty;
+  mutable cv::Rect rectified_roi;
+
+  Cache()
+    : distortion_state(UNKNOWN),
+      distortion_model(UNKNOWN_MODEL),
+      full_maps_dirty(true),
+      reduced_maps_dirty(true),
+      unrectify_full_maps_dirty(true),
+      unrectify_reduced_maps_dirty(true),
+      rectified_roi_dirty(true)
+  {
+  }
+};
+
+PinholeCameraModel::PinholeCameraModel()
+{
+}
+
+PinholeCameraModel& PinholeCameraModel::operator=(const PinholeCameraModel& other)
+{
+  if (other.initialized())
+    this->fromCameraInfo(other.cameraInfo());
+  return *this;
+}
+
+PinholeCameraModel::PinholeCameraModel(const PinholeCameraModel& other)
+{
+  if (other.initialized())
+    fromCameraInfo(other.cam_info_);
+}
+
+// For uint32_t, string, bool...
+template<typename T>
+bool update(const T& new_val, T& my_val)
+{
+  if (my_val == new_val)
+    return false;
+  my_val = new_val;
+  return true;
+}
+
+// For std::vector
+template<typename MatT>
+bool updateMat(const MatT& new_mat, MatT& my_mat, cv::Mat_<double>& cv_mat, int rows, int cols)
+{
+  if ((my_mat == new_mat) && (my_mat.size() == cv_mat.rows*cv_mat.cols))
+    return false;
+  my_mat = new_mat;
+  // D may be empty if camera is uncalibrated or distortion model is non-standard
+  cv_mat = (my_mat.size() == 0) ? cv::Mat_<double>() : cv::Mat_<double>(rows, cols, &my_mat[0]);
+  return true;
+}
+
+template<typename MatT, typename MatU>
+bool updateMat(const MatT& new_mat, MatT& my_mat, MatU& cv_mat)
+{
+  if ((my_mat == new_mat) && (my_mat.size() == cv_mat.rows*cv_mat.cols))
+    return false;
+  my_mat = new_mat;
+  // D may be empty if camera is uncalibrated or distortion model is non-standard
+  cv_mat = MatU(&my_mat[0]);
+  return true;
+}
+
+bool PinholeCameraModel::fromCameraInfo(const sensor_msgs::CameraInfo& msg)
+{
+  // Create our repository of cached data (rectification maps, etc.)
+  if (!cache_)
+#ifdef BOOST_SHARED_PTR_HPP_INCLUDED
+    cache_ = boost::make_shared<Cache>();
+#else
+    cache_ = std::make_shared<Cache>();
+#endif
+
+  // Binning = 0 is considered the same as binning = 1 (no binning).
+  uint32_t binning_x = msg.binning_x ? msg.binning_x : 1;
+  uint32_t binning_y = msg.binning_y ? msg.binning_y : 1;
+
+  // ROI all zeros is considered the same as full resolution.
+  sensor_msgs::RegionOfInterest roi = msg.roi;
+  if (roi.x_offset == 0 && roi.y_offset == 0 && roi.width == 0 && roi.height == 0) {
+    roi.width  = msg.width;
+    roi.height = msg.height;
+  }
+
+  // Update time stamp (and frame_id if that changes for some reason)
+  cam_info_.header = msg.header;
+
+  // Update any parameters that have changed. The full rectification maps are
+  // invalidated by any change in the calibration parameters OR binning.
+  bool full_dirty = false;
+  full_dirty |= update(msg.height, cam_info_.height);
+  full_dirty |= update(msg.width,  cam_info_.width);
+  full_dirty |= update(msg.distortion_model, cam_info_.distortion_model);
+  full_dirty |= updateMat(msg.D, cam_info_.D, D_, 1, msg.D.size());
+  full_dirty |= updateMat(msg.K, cam_info_.K, K_full_);
+  full_dirty |= updateMat(msg.R, cam_info_.R, R_);
+  full_dirty |= updateMat(msg.P, cam_info_.P, P_full_);
+  full_dirty |= update(binning_x, cam_info_.binning_x);
+  full_dirty |= update(binning_y, cam_info_.binning_y);
+  cache_->full_maps_dirty |= full_dirty;
+  cache_->unrectify_full_maps_dirty |= full_dirty;
+
+  // The reduced rectification maps are invalidated by any of the above or a
+  // change in ROI.
+  bool reduced_dirty = full_dirty;
+  reduced_dirty |= update(roi.x_offset,   cam_info_.roi.x_offset);
+  reduced_dirty |= update(roi.y_offset,   cam_info_.roi.y_offset);
+  reduced_dirty |= update(roi.height,     cam_info_.roi.height);
+  reduced_dirty |= update(roi.width,      cam_info_.roi.width);
+  reduced_dirty |= update(roi.do_rectify, cam_info_.roi.do_rectify);
+  cache_->reduced_maps_dirty |= reduced_dirty;
+  cache_->reduced_maps_dirty |= cache_->full_maps_dirty;
+  cache_->unrectify_reduced_maps_dirty |= reduced_dirty;
+  cache_->unrectify_reduced_maps_dirty |= cache_->unrectify_full_maps_dirty;
+
+  // As is the rectified ROI
+  cache_->rectified_roi_dirty |= reduced_dirty;
+
+  // Figure out how to handle the distortion
+  if (cam_info_.distortion_model == sensor_msgs::distortion_models::PLUMB_BOB ||
+      cam_info_.distortion_model == sensor_msgs::distortion_models::RATIONAL_POLYNOMIAL ||
+      cam_info_.distortion_model == sensor_msgs::distortion_models::EQUIDISTANT) {
+    // If any distortion coefficient is non-zero, then need to apply the distortion
+    cache_->distortion_state = NONE;
+    for (size_t i = 0; i < cam_info_.D.size(); ++i)
+    {
+      if (cam_info_.D[i] != 0)
+      {
+        cache_->distortion_state = CALIBRATED;
+        break;
+      }
+    }
+  }
+  else
+    cache_->distortion_state = UNKNOWN;
+
+  // Get the distortion model, if supported
+  if (cam_info_.distortion_model == sensor_msgs::distortion_models::PLUMB_BOB ||
+      cam_info_.distortion_model == sensor_msgs::distortion_models::RATIONAL_POLYNOMIAL) {
+    cache_->distortion_model = PLUMB_BOB_OR_RATIONAL_POLYNOMIAL;
+  }
+  else if(cam_info_.distortion_model == sensor_msgs::distortion_models::EQUIDISTANT) {
+    cache_->distortion_model = EQUIDISTANT;
+  }
+  else
+    cache_->distortion_model = UNKNOWN_MODEL;
+
+  // If necessary, create new K_ and P_ adjusted for binning and ROI
+  /// @todo Calculate and use rectified ROI
+  bool adjust_binning = (binning_x > 1) || (binning_y > 1);
+  bool adjust_roi = (roi.x_offset != 0) || (roi.y_offset != 0);
+
+  if (!adjust_binning && !adjust_roi) {
+    K_ = K_full_;
+    P_ = P_full_;
+  }
+  else {
+    K_ = K_full_;
+    P_ = P_full_;
+
+    // ROI is in full image coordinates, so change it first
+    if (adjust_roi) {
+      // Move principal point by the offset
+      /// @todo Adjust P by rectified ROI instead
+      K_(0,2) -= roi.x_offset;
+      K_(1,2) -= roi.y_offset;
+      P_(0,2) -= roi.x_offset;
+      P_(1,2) -= roi.y_offset;
+    }
+
+    if (binning_x > 1) {
+      double scale_x = 1.0 / binning_x;
+      K_(0,0) *= scale_x;
+      K_(0,2) *= scale_x;
+      P_(0,0) *= scale_x;
+      P_(0,2) *= scale_x;
+      P_(0,3) *= scale_x;
+    }
+    if (binning_y > 1) {
+      double scale_y = 1.0 / binning_y;
+      K_(1,1) *= scale_y;
+      K_(1,2) *= scale_y;
+      P_(1,1) *= scale_y;
+      P_(1,2) *= scale_y;
+      P_(1,3) *= scale_y;
+    }
+  }
+
+  return reduced_dirty;
+}
+
+bool PinholeCameraModel::fromCameraInfo(const sensor_msgs::CameraInfoConstPtr& msg)
+{
+  return fromCameraInfo(*msg);
+}
+
+cv::Size PinholeCameraModel::fullResolution() const
+{
+  assert( initialized() );
+  return cv::Size(cam_info_.width, cam_info_.height);
+}
+
+cv::Size PinholeCameraModel::reducedResolution() const
+{
+  assert( initialized() );
+
+  cv::Rect roi = rectifiedRoi();
+  return cv::Size(roi.width / binningX(), roi.height / binningY());
+}
+
+cv::Point2d PinholeCameraModel::toFullResolution(const cv::Point2d& uv_reduced) const
+{
+  cv::Rect roi = rectifiedRoi();
+  return cv::Point2d(uv_reduced.x * binningX() + roi.x,
+                     uv_reduced.y * binningY() + roi.y);
+}
+
+cv::Rect PinholeCameraModel::toFullResolution(const cv::Rect& roi_reduced) const
+{
+  cv::Rect roi = rectifiedRoi();
+  return cv::Rect(roi_reduced.x * binningX() + roi.x,
+                  roi_reduced.y * binningY() + roi.y,
+                  roi_reduced.width  * binningX(),
+                  roi_reduced.height * binningY());
+}
+
+cv::Point2d PinholeCameraModel::toReducedResolution(const cv::Point2d& uv_full) const
+{
+  cv::Rect roi = rectifiedRoi();
+  return cv::Point2d((uv_full.x - roi.x) / binningX(),
+                     (uv_full.y - roi.y) / binningY());
+}
+
+cv::Rect PinholeCameraModel::toReducedResolution(const cv::Rect& roi_full) const
+{
+  cv::Rect roi = rectifiedRoi();
+  return cv::Rect((roi_full.x - roi.x) / binningX(),
+                  (roi_full.y - roi.y) / binningY(),
+                  roi_full.width  / binningX(),
+                  roi_full.height / binningY());
+}
+
+cv::Rect PinholeCameraModel::rawRoi() const
+{
+  assert( initialized() );
+
+  return cv::Rect(cam_info_.roi.x_offset, cam_info_.roi.y_offset,
+                  cam_info_.roi.width, cam_info_.roi.height);
+}
+
+cv::Rect PinholeCameraModel::rectifiedRoi() const
+{
+  assert( initialized() );
+
+  if (cache_->rectified_roi_dirty)
+  {
+    if (!cam_info_.roi.do_rectify)
+      cache_->rectified_roi = rawRoi();
+    else
+      cache_->rectified_roi = rectifyRoi(rawRoi());
+    cache_->rectified_roi_dirty = false;
+  }
+  return cache_->rectified_roi;
+}
+
+cv::Point2d PinholeCameraModel::project3dToPixel(const cv::Point3d& xyz) const
+{
+  assert( initialized() );
+  assert(P_(2, 3) == 0.0); // Calibrated stereo cameras should be in the same plane
+
+  // [U V W]^T = P * [X Y Z 1]^T
+  // u = U/W
+  // v = V/W
+  cv::Point2d uv_rect;
+  uv_rect.x = (fx()*xyz.x + Tx()) / xyz.z + cx();
+  uv_rect.y = (fy()*xyz.y + Ty()) / xyz.z + cy();
+  return uv_rect;
+}
+
+cv::Point3d PinholeCameraModel::projectPixelTo3dRay(const cv::Point2d& uv_rect) const
+{
+  return projectPixelTo3dRay(uv_rect, P_);
+}
+
+cv::Point3d PinholeCameraModel::projectPixelTo3dRay(const cv::Point2d& uv_rect, const cv::Matx34d& P) const
+{
+  assert( initialized() );
+
+  const double& fx = P(0,0);
+  const double& fy = P(1,1);
+  const double& cx = P(0,2);
+  const double& cy = P(1,2);
+  const double& Tx = P(0,3);
+  const double& Ty = P(1,3);
+
+  cv::Point3d ray;
+  ray.x = (uv_rect.x - cx - Tx) / fx;
+  ray.y = (uv_rect.y - cy - Ty) / fy;
+  ray.z = 1.0;
+  return ray;
+}
+
+void PinholeCameraModel::rectifyImage(const cv::Mat& raw, cv::Mat& rectified, int interpolation) const
+{
+  assert( initialized() );
+
+  switch (cache_->distortion_state) {
+    case NONE:
+      raw.copyTo(rectified);
+      break;
+    case CALIBRATED:
+      initRectificationMaps();
+      if (raw.depth() == CV_32F || raw.depth() == CV_64F)
+      {
+        cv::remap(raw, rectified, cache_->reduced_map1, cache_->reduced_map2, interpolation, cv::BORDER_CONSTANT, std::numeric_limits<float>::quiet_NaN());
+      }
+      else {
+        cv::remap(raw, rectified, cache_->reduced_map1, cache_->reduced_map2, interpolation);
+      }
+      break;
+    default:
+      assert(cache_->distortion_state == UNKNOWN);
+      throw Exception("Cannot call rectifyImage when distortion is unknown.");
+  }
+}
+
+void PinholeCameraModel::unrectifyImage(const cv::Mat& rectified, cv::Mat& raw, int interpolation) const
+{
+  assert( initialized() );
+
+  switch (cache_->distortion_state) {
+    case NONE:
+      rectified.copyTo(raw);
+      break;
+    case CALIBRATED:
+      initUnrectificationMaps();
+      if (rectified.depth() == CV_32F || rectified.depth() == CV_64F)
+      {
+        cv::remap(rectified, raw, cache_->unrectify_reduced_map1, cache_->unrectify_reduced_map2, interpolation, cv::BORDER_CONSTANT, std::numeric_limits<float>::quiet_NaN());
+      }
+      else {
+        cv::remap(rectified, raw, cache_->unrectify_reduced_map1, cache_->unrectify_reduced_map2, interpolation);
+      }
+      break;
+    default:
+      assert(cache_->distortion_state == UNKNOWN);
+      throw Exception("Cannot call rectifyImage when distortion is unknown.");
+  }
+}
+
+cv::Point2d PinholeCameraModel::rectifyPoint(const cv::Point2d& uv_raw) const
+{
+  return rectifyPoint(uv_raw, K_, P_);
+}
+
+cv::Point2d PinholeCameraModel::rectifyPoint(const cv::Point2d& uv_raw, const cv::Matx33d& K, const cv::Matx34d& P) const
+{
+  assert( initialized() );
+
+  if (cache_->distortion_state == NONE)
+    return uv_raw;
+  if (cache_->distortion_state == UNKNOWN)
+    throw Exception("Cannot call rectifyPoint when distortion is unknown.");
+  assert(cache_->distortion_state == CALIBRATED);
+
+  /// @todo cv::undistortPoints requires the point data to be float, should allow double
+  cv::Point2f raw32 = uv_raw, rect32;
+  const cv::Mat src_pt(1, 1, CV_32FC2, &raw32.x);
+  cv::Mat dst_pt(1, 1, CV_32FC2, &rect32.x);
+
+  switch (cache_->distortion_model) {
+    case PLUMB_BOB_OR_RATIONAL_POLYNOMIAL:
+      cv::undistortPoints(src_pt, dst_pt, K, D_, R_, P);
+      break;
+    case EQUIDISTANT:
+      cv::fisheye::undistortPoints(src_pt, dst_pt, K, D_, R_, P);
+      break;
+    default:
+      assert(cache_->distortion_model == UNKNOWN_MODEL);
+      throw Exception("Wrong distortion model. Supported models: PLUMB_BOB, RATIONAL_POLYNOMIAL and EQUIDISTANT.");
+  }
+  return rect32;
+}
+
+cv::Point2d PinholeCameraModel::unrectifyPoint(const cv::Point2d& uv_rect) const
+{
+  return unrectifyPoint(uv_rect, K_, P_);
+}
+
+cv::Point2d PinholeCameraModel::unrectifyPoint(const cv::Point2d& uv_rect, const cv::Matx33d& K, const cv::Matx34d& P) const
+{
+  assert( initialized() );
+
+  if (cache_->distortion_state == NONE)
+    return uv_rect;
+  if (cache_->distortion_state == UNKNOWN)
+    throw Exception("Cannot call unrectifyPoint when distortion is unknown.");
+  assert(cache_->distortion_state == CALIBRATED);
+
+  // Convert to a ray
+  cv::Point3d ray = projectPixelTo3dRay(uv_rect, P);
+
+  // Project the ray on the image
+  cv::Mat r_vec, t_vec = cv::Mat_<double>::zeros(3, 1);
+  cv::Rodrigues(R_.t(), r_vec);
+  std::vector<cv::Point2d> image_point;
+
+  switch (cache_->distortion_model) {
+    case PLUMB_BOB_OR_RATIONAL_POLYNOMIAL:
+      cv::projectPoints(std::vector<cv::Point3d>(1, ray), r_vec, t_vec, K, D_, image_point);
+      break;
+    case EQUIDISTANT:
+      cv::fisheye::projectPoints(std::vector<cv::Point3d>(1, ray), image_point, r_vec, t_vec, K, D_);
+      break;
+    default:
+      assert(cache_->distortion_model == UNKNOWN_MODEL);
+      throw Exception("Wrong distortion model. Supported models: PLUMB_BOB, RATIONAL_POLYNOMIAL and EQUIDISTANT.");
+  }
+
+  return image_point[0];
+}
+
+cv::Rect PinholeCameraModel::rectifyRoi(const cv::Rect& roi_raw) const
+{
+  assert( initialized() );
+
+  /// @todo Actually implement "best fit" as described by REP 104.
+
+  // For now, just unrectify the four corners and take the bounding box.
+  // Since ROI is specified in unbinned coordinates (see REP-104), this has to use K_full_ and P_full_.
+  cv::Point2d rect_tl = rectifyPoint(cv::Point2d(roi_raw.x, roi_raw.y), K_full_, P_full_);
+  cv::Point2d rect_tr = rectifyPoint(cv::Point2d(roi_raw.x + roi_raw.width, roi_raw.y), K_full_, P_full_);
+  cv::Point2d rect_br = rectifyPoint(cv::Point2d(roi_raw.x + roi_raw.width,
+                                                 roi_raw.y + roi_raw.height), K_full_, P_full_);
+  cv::Point2d rect_bl = rectifyPoint(cv::Point2d(roi_raw.x, roi_raw.y + roi_raw.height), K_full_, P_full_);
+
+  cv::Point roi_tl(std::ceil (std::min(rect_tl.x, rect_bl.x)),
+                   std::ceil (std::min(rect_tl.y, rect_tr.y)));
+  cv::Point roi_br(std::floor(std::max(rect_tr.x, rect_br.x)),
+                   std::floor(std::max(rect_bl.y, rect_br.y)));
+
+  return cv::Rect(roi_tl.x, roi_tl.y, roi_br.x - roi_tl.x, roi_br.y - roi_tl.y);
+}
+
+cv::Rect PinholeCameraModel::unrectifyRoi(const cv::Rect& roi_rect) const
+{
+  assert( initialized() );
+
+  /// @todo Actually implement "best fit" as described by REP 104.
+
+  // For now, just unrectify the four corners and take the bounding box.
+  cv::Point2d raw_tl = unrectifyPoint(cv::Point2d(roi_rect.x, roi_rect.y));
+  cv::Point2d raw_tr = unrectifyPoint(cv::Point2d(roi_rect.x + roi_rect.width, roi_rect.y));
+  cv::Point2d raw_br = unrectifyPoint(cv::Point2d(roi_rect.x + roi_rect.width,
+                                                  roi_rect.y + roi_rect.height));
+  cv::Point2d raw_bl = unrectifyPoint(cv::Point2d(roi_rect.x, roi_rect.y + roi_rect.height));
+
+  cv::Point roi_tl(std::floor(std::min(raw_tl.x, raw_bl.x)),
+                   std::floor(std::min(raw_tl.y, raw_tr.y)));
+  cv::Point roi_br(std::ceil (std::max(raw_tr.x, raw_br.x)),
+                   std::ceil (std::max(raw_bl.y, raw_br.y)));
+
+  return cv::Rect(roi_tl.x, roi_tl.y, roi_br.x - roi_tl.x, roi_br.y - roi_tl.y);
+}
+
+void PinholeCameraModel::initRectificationMaps() const
+{
+  /// @todo For large binning settings, can drop extra rows/cols at bottom/right boundary.
+  /// Make sure we're handling that 100% correctly.
+
+  if (cache_->full_maps_dirty) {
+    // Create the full-size map at the binned resolution
+    /// @todo Should binned resolution, K, P be part of public API?
+    cv::Size binned_resolution = fullResolution();
+    binned_resolution.width  /= binningX();
+    binned_resolution.height /= binningY();
+
+    cv::Matx33d K_binned;
+    cv::Matx34d P_binned;
+    if (binningX() == 1 && binningY() == 1) {
+      K_binned = K_full_;
+      P_binned = P_full_;
+    }
+    else {
+      K_binned = K_full_;
+      P_binned = P_full_;
+      if (binningX() > 1) {
+        double scale_x = 1.0 / binningX();
+        K_binned(0,0) *= scale_x;
+        K_binned(0,2) *= scale_x;
+        P_binned(0,0) *= scale_x;
+        P_binned(0,2) *= scale_x;
+        P_binned(0,3) *= scale_x;
+      }
+      if (binningY() > 1) {
+        double scale_y = 1.0 / binningY();
+        K_binned(1,1) *= scale_y;
+        K_binned(1,2) *= scale_y;
+        P_binned(1,1) *= scale_y;
+        P_binned(1,2) *= scale_y;
+        P_binned(1,3) *= scale_y;
+      }
+    }
+
+    switch (cache_->distortion_model) {
+      case PLUMB_BOB_OR_RATIONAL_POLYNOMIAL:
+        // Note: m1type=CV_16SC2 to use fast fixed-point maps (see cv::remap)
+        cv::initUndistortRectifyMap(K_binned, D_, R_, P_binned, binned_resolution,
+                                    CV_16SC2, cache_->full_map1, cache_->full_map2);
+        break;
+      case EQUIDISTANT:
+        cv::fisheye::initUndistortRectifyMap(K_binned,D_, R_, P_binned, binned_resolution,
+                                             CV_16SC2, cache_->full_map1, cache_->full_map2);
+        break;
+      default:
+        assert(cache_->distortion_model == UNKNOWN_MODEL);
+        throw Exception("Wrong distortion model. Supported models: PLUMB_BOB, RATIONAL_POLYNOMIAL and EQUIDISTANT.");
+    }
+    cache_->full_maps_dirty = false;
+  }
+
+  if (cache_->reduced_maps_dirty) {
+    /// @todo Use rectified ROI
+    cv::Rect roi(cam_info_.roi.x_offset, cam_info_.roi.y_offset,
+                 cam_info_.roi.width, cam_info_.roi.height);
+    if (roi.x != 0 || roi.y != 0 ||
+        (roi.height != 0 && roi.height != (int)cam_info_.height) ||
+        (roi.width != 0 && roi.width  != (int)cam_info_.width)) {
+
+      // map1 contains integer (x,y) offsets, which we adjust by the ROI offset
+      // map2 contains LUT index for subpixel interpolation, which we can leave as-is
+      roi.x /= binningX();
+      roi.y /= binningY();
+      roi.width  /= binningX();
+      roi.height /= binningY();
+      cache_->reduced_map1 = cache_->full_map1(roi) - cv::Scalar(roi.x, roi.y);
+      cache_->reduced_map2 = cache_->full_map2(roi);
+    }
+    else {
+      // Otherwise we're rectifying the full image
+      cache_->reduced_map1 = cache_->full_map1;
+      cache_->reduced_map2 = cache_->full_map2;
+    }
+    cache_->reduced_maps_dirty = false;
+  }
+}
+
+void PinholeCameraModel::initUnrectificationMaps() const
+{
+  /// @todo For large binning settings, can drop extra rows/cols at bottom/right boundary.
+  /// Make sure we're handling that 100% correctly.
+
+  if (cache_->unrectify_full_maps_dirty) {
+    // Create the full-size map at the binned resolution
+    /// @todo Should binned resolution, K, P be part of public API?
+    cv::Size binned_resolution = fullResolution();
+    binned_resolution.width  /= binningX();
+    binned_resolution.height /= binningY();
+
+    cv::Matx33d K_binned;
+    cv::Matx34d P_binned;
+    if (binningX() == 1 && binningY() == 1) {
+      K_binned = K_full_;
+      P_binned = P_full_;
+    }
+    else {
+      K_binned = K_full_;
+      P_binned = P_full_;
+      if (binningX() > 1) {
+        double scale_x = 1.0 / binningX();
+        K_binned(0,0) *= scale_x;
+        K_binned(0,2) *= scale_x;
+        P_binned(0,0) *= scale_x;
+        P_binned(0,2) *= scale_x;
+        P_binned(0,3) *= scale_x;
+      }
+      if (binningY() > 1) {
+        double scale_y = 1.0 / binningY();
+        K_binned(1,1) *= scale_y;
+        K_binned(1,2) *= scale_y;
+        P_binned(1,1) *= scale_y;
+        P_binned(1,2) *= scale_y;
+        P_binned(1,3) *= scale_y;
+      }
+    }
+
+    cv::Mat float_map_x(binned_resolution.height, binned_resolution.width, CV_32FC1);
+    cv::Mat float_map_y(binned_resolution.height, binned_resolution.width, CV_32FC1);
+    for (size_t x = 0; x < binned_resolution.width; x++) {
+      for (size_t y = 0; y < binned_resolution.height; y++) {
+        cv::Point2f uv_raw(x, y), uv_rect;
+        uv_rect = rectifyPoint(uv_raw, K_binned, P_binned);
+        float_map_x.at<float>(y, x) = uv_rect.x;
+        float_map_y.at<float>(y, x) = uv_rect.y;
+      }
+    }
+    // Note: m1type=CV_16SC2 to use fast fixed-point maps (see cv::remap)
+    convertMaps(float_map_x, float_map_y, cache_->unrectify_full_map1, cache_->unrectify_full_map2, CV_16SC2);
+    cache_->unrectify_full_maps_dirty = false;
+  }
+
+  if (cache_->unrectify_reduced_maps_dirty) {
+    /// @todo Use rectified ROI
+    cv::Rect roi(cam_info_.roi.x_offset, cam_info_.roi.y_offset,
+                 cam_info_.roi.width, cam_info_.roi.height);
+    if (roi.x != 0 || roi.y != 0 ||
+        (roi.height != 0 && roi.height != (int)cam_info_.height) ||
+        (roi.width != 0 && roi.width  != (int)cam_info_.width)) {
+
+      // map1 contains integer (x,y) offsets, which we adjust by the ROI offset
+      // map2 contains LUT index for subpixel interpolation, which we can leave as-is
+      roi.x /= binningX();
+      roi.y /= binningY();
+      roi.width  /= binningX();
+      roi.height /= binningY();
+      cache_->unrectify_reduced_map1 = cache_->unrectify_full_map1(roi) - cv::Scalar(roi.x, roi.y);
+      cache_->unrectify_reduced_map2 = cache_->unrectify_full_map2(roi);
+    }
+    else {
+      // Otherwise we're rectifying the full image
+      cache_->unrectify_reduced_map1 = cache_->unrectify_full_map1;
+      cache_->unrectify_reduced_map2 = cache_->unrectify_full_map2;
+    }
+    cache_->unrectify_reduced_maps_dirty = false;
+  }
+}
+
+} //namespace image_geometry
--- /dev/null
+++ ros-noetic-image-geometry-1.16.2/src/stereo_camera_model.cpp
@@ -0,0 +1,141 @@
+#include "image_geometry/stereo_camera_model.h"
+#include <opencv2/calib3d/calib3d.hpp>
+
+namespace image_geometry {
+
+StereoCameraModel::StereoCameraModel()
+  : Q_(0.0)
+{
+  Q_(0,0) = Q_(1,1) = 1.0;
+}
+
+StereoCameraModel::StereoCameraModel(const StereoCameraModel& other)
+  : left_(other.left_), right_(other.right_),
+    Q_(0.0)
+{
+  Q_(0,0) = Q_(1,1) = 1.0;
+  if (other.initialized())
+    updateQ();
+}
+
+StereoCameraModel& StereoCameraModel::operator=(const StereoCameraModel& other)
+{
+  if (other.initialized())
+    this->fromCameraInfo(other.left_.cameraInfo(), other.right_.cameraInfo());
+  return *this;
+}
+
+bool StereoCameraModel::fromCameraInfo(const sensor_msgs::CameraInfo& left,
+                                       const sensor_msgs::CameraInfo& right)
+{
+  bool changed_left  = left_.fromCameraInfo(left);
+  bool changed_right = right_.fromCameraInfo(right);
+  bool changed = changed_left || changed_right;
+
+  // Note: don't require identical time stamps to allow imperfectly synced stereo.
+  assert( left_.tfFrame() == right_.tfFrame() );
+  assert( left_.fx() == right_.fx() );
+  assert( left_.fy() == right_.fy() );
+  assert( left_.cy() == right_.cy() );
+  // cx may differ for verged cameras
+
+  if (changed)
+    updateQ();
+
+  return changed;
+}
+
+bool StereoCameraModel::fromCameraInfo(const sensor_msgs::CameraInfoConstPtr& left,
+                                       const sensor_msgs::CameraInfoConstPtr& right)
+{
+  return fromCameraInfo(*left, *right);
+}
+
+void StereoCameraModel::updateQ()
+{
+  // Update variable fields of reprojection matrix
+  /*
+    From Springer Handbook of Robotics, p. 524:
+
+         [ Fx    0  Cx   0   ]
+    P  = [ 0     Fy Cy   0   ]
+         [ 0     0  1    0   ]
+
+         [ Fx    0  Cx' FxTx ]
+    P' = [ 0     Fy Cy   0    ]
+         [ 0     0  1    0    ]
+    where primed parameters are from the left projection matrix, unprimed from the right.
+
+    [u   v 1]^T = P  * [x y z 1]^T
+    [u-d v 1]^T = P' * [x y z 1]^T
+
+    Combining the two equations above results in the following equation
+
+    [u v u-d 1]^T = [ Fx   0    Cx   0    ] * [ x y z 1]^T
+                    [ 0    Fy   Cy   0    ]
+                    [ Fx   0    Cx'  FxTx ]
+                    [ 0    0    1    0    ]
+
+    Subtracting the 3rd from from the first and inverting the expression
+    results in the following equation.
+
+    [x y z 1]^T = Q * [u v d 1]^T
+
+    Where Q is defined as
+
+    Q = [ FyTx  0     0   -FyCxTx     ]
+        [ 0     FxTx  0   -FxCyTx     ]
+        [ 0     0     0    FxFyTx     ]
+        [ 0     0     -Fy  Fy(Cx-Cx') ]
+
+   Using the assumption Fx = Fy Q can be simplified to the following. But for
+   compatibility with stereo cameras with different focal lengths we will use
+   the full Q matrix.
+
+        [ 1 0   0      -Cx      ]
+    Q = [ 0 1   0      -Cy      ]
+        [ 0 0   0       Fx      ]
+        [ 0 0 -1/Tx (Cx-Cx')/Tx ]
+
+    Disparity = x_left - x_right
+
+    For compatibility with stereo cameras with different focal lengths we will use
+    the full Q matrix.
+
+   */
+  double Tx = -baseline(); // The baseline member negates our Tx. Undo this negation
+  Q_(0,0) =  left_.fy() * Tx;
+  Q_(0,3) = -left_.fy() * left_.cx() * Tx;
+  Q_(1,1) =  left_.fx() * Tx;
+  Q_(1,3) = -left_.fx() * left_.cy() * Tx;
+  Q_(2,3) =  left_.fx() * left_.fy() * Tx;
+  Q_(3,2) = -left_.fy();
+  Q_(3,3) =  left_.fy() * (left_.cx() - right_.cx()); // zero when disparities are pre-adjusted
+}
+
+void StereoCameraModel::projectDisparityTo3d(const cv::Point2d& left_uv_rect, float disparity,
+                                             cv::Point3d& xyz) const
+{
+  assert( initialized() );
+
+  // Do the math inline:
+  // [X Y Z W]^T = Q * [u v d 1]^T
+  // Point = (X/W, Y/W, Z/W)
+  // cv::perspectiveTransform could be used but with more overhead.
+  double u = left_uv_rect.x, v = left_uv_rect.y;
+  cv::Point3d XYZ( (Q_(0,0) * u) + Q_(0,3), (Q_(1,1) * v) + Q_(1,3), Q_(2,3));
+  double W = Q_(3,2)*disparity + Q_(3,3);
+  xyz = XYZ * (1.0/W);
+}
+
+const double StereoCameraModel::MISSING_Z = 10000.;
+
+void StereoCameraModel::projectDisparityImageTo3d(const cv::Mat& disparity, cv::Mat& point_cloud,
+                                                  bool handleMissingValues) const
+{
+  assert( initialized() );
+
+  cv::reprojectImageTo3D(disparity, point_cloud, Q_, handleMissingValues);
+}
+
+} //namespace image_geometry
--- /dev/null
+++ ros-noetic-image-geometry-1.16.2/test/CMakeLists.txt
@@ -0,0 +1,7 @@
+catkin_add_nosetests(directed.py)
+
+catkin_add_gtest(${PROJECT_NAME}-utest utest.cpp)
+target_link_libraries(${PROJECT_NAME}-utest ${PROJECT_NAME} ${OpenCV_LIBS})
+
+catkin_add_gtest(${PROJECT_NAME}-utest-equi utest_equi.cpp)
+target_link_libraries(${PROJECT_NAME}-utest-equi ${PROJECT_NAME} ${OpenCV_LIBS})
--- /dev/null
+++ ros-noetic-image-geometry-1.16.2/test/directed.py
@@ -0,0 +1,77 @@
+from __future__ import print_function
+
+import rostest
+import rospy
+import unittest
+import sensor_msgs.msg
+
+from image_geometry import PinholeCameraModel, StereoCameraModel
+
+class TestDirected(unittest.TestCase):
+
+    def setUp(self):
+        pass
+
+    def test_monocular(self):
+        ci = sensor_msgs.msg.CameraInfo()
+        ci.width = 640
+        ci.height = 480
+        print(ci)
+        cam = PinholeCameraModel()
+        cam.fromCameraInfo(ci)
+        print(cam.rectifyPoint((0, 0)))
+
+        print(cam.project3dToPixel((0,0,0)))
+
+    def test_stereo(self):
+        lmsg = sensor_msgs.msg.CameraInfo()
+        rmsg = sensor_msgs.msg.CameraInfo()
+        for m in (lmsg, rmsg):
+            m.width = 640
+            m.height = 480
+
+        # These parameters taken from a real camera calibration
+        lmsg.D =  [-0.363528858080088, 0.16117037733986861, -8.1109585007538829e-05, -0.00044776712298447841, 0.0]
+        lmsg.K =  [430.15433020105519, 0.0, 311.71339830549732, 0.0, 430.60920415473657, 221.06824942698509, 0.0, 0.0, 1.0]
+        lmsg.R =  [0.99806560714807102, 0.0068562422224214027, 0.061790256276695904, -0.0067522959054715113, 0.99997541519165112, -0.0018909025066874664, -0.061801701660692349, 0.0014700186639396652, 0.99808736527268516]
+        lmsg.P =  [295.53402059708782, 0.0, 285.55760765075684, 0.0, 0.0, 295.53402059708782, 223.29617881774902, 0.0, 0.0, 0.0, 1.0, 0.0]
+
+        rmsg.D =  [-0.3560641041112021, 0.15647260261553159, -0.00016442960757099968, -0.00093175810713916221]
+        rmsg.K =  [428.38163131344191, 0.0, 327.95553847249192, 0.0, 428.85728580588329, 217.54828640915309, 0.0, 0.0, 1.0]
+        rmsg.R =  [0.9982082576219119, 0.0067433328293516528, 0.059454199832973849, -0.0068433268864187356, 0.99997549128605434, 0.0014784127772287513, -0.059442773257581252, -0.0018826283666309878, 0.99822993965212292]
+        rmsg.P =  [295.53402059708782, 0.0, 285.55760765075684, -26.507895206214123, 0.0, 295.53402059708782, 223.29617881774902, 0.0, 0.0, 0.0, 1.0, 0.0]
+
+        cam = StereoCameraModel()
+        cam.fromCameraInfo(lmsg, rmsg)
+
+        for x in (16, 320, m.width - 16):
+            for y in (16, 240, m.height - 16):
+                for d in range(1, 10):
+                    pt3d = cam.projectPixelTo3d((x, y), d)
+                    ((lx, ly), (rx, ry)) = cam.project3dToPixel(pt3d)
+                    self.assertAlmostEqual(y, ly, 3)
+                    self.assertAlmostEqual(y, ry, 3)
+                    self.assertAlmostEqual(x, lx, 3)
+                    self.assertAlmostEqual(x, rx + d, 3)
+        
+        u = 100.0
+        v = 200.0
+        du = 17.0
+        dv = 23.0
+        Z = 2.0
+        xyz0 = cam.left.projectPixelTo3dRay((u, v))
+        xyz0 = (xyz0[0] * (Z / xyz0[2]), xyz0[1] * (Z / xyz0[2]), Z)
+        xyz1 = cam.left.projectPixelTo3dRay((u + du, v + dv))
+        xyz1 = (xyz1[0] * (Z / xyz1[2]), xyz1[1] * (Z / xyz1[2]), Z)
+        self.assertAlmostEqual(cam.left.getDeltaU(xyz1[0] - xyz0[0], Z), du, 3)
+        self.assertAlmostEqual(cam.left.getDeltaV(xyz1[1] - xyz0[1], Z), dv, 3)
+        self.assertAlmostEqual(cam.left.getDeltaX(du, Z), xyz1[0] - xyz0[0], 3)
+        self.assertAlmostEqual(cam.left.getDeltaY(dv, Z), xyz1[1] - xyz0[1], 3)
+
+if __name__ == '__main__':
+    if 1:
+        rostest.unitrun('image_geometry', 'directed', TestDirected)
+    else:
+        suite = unittest.TestSuite()
+        suite.addTest(TestDirected('test_stereo'))
+        unittest.TextTestRunner(verbosity=2).run(suite)
--- /dev/null
+++ ros-noetic-image-geometry-1.16.2/test/utest.cpp
@@ -0,0 +1,464 @@
+#include "image_geometry/pinhole_camera_model.h"
+#include <sensor_msgs/distortion_models.h>
+#include <gtest/gtest.h>
+
+/// @todo Tests with simple values (R = identity, D = 0, P = K or simple scaling)
+/// @todo Test projection functions for right stereo values, P(:,3) != 0
+/// @todo Tests for rectifyImage
+/// @todo Tests using ROI, needs support from PinholeCameraModel
+/// @todo Tests for StereoCameraModel
+
+class PinholeTest : public testing::Test
+{
+protected:
+  virtual void SetUp()
+  {
+    /// @todo Just load these from file
+    // These parameters taken from a real camera calibration
+    double D[] = {-0.363528858080088, 0.16117037733986861, -8.1109585007538829e-05, -0.00044776712298447841, 0.0};
+    double K[] = {430.15433020105519,                0.0, 311.71339830549732,
+                                 0.0, 430.60920415473657, 221.06824942698509,
+                                 0.0,                0.0,                1.0};
+    double R[] = {0.99806560714807102, 0.0068562422224214027, 0.061790256276695904,
+                  -0.0067522959054715113, 0.99997541519165112, -0.0018909025066874664,
+                  -0.061801701660692349, 0.0014700186639396652, 0.99808736527268516};
+    double P[] = {295.53402059708782, 0.0, 285.55760765075684, 0.0,
+                  0.0, 295.53402059708782, 223.29617881774902, 0.0,
+                  0.0, 0.0, 1.0, 0.0};
+
+    cam_info_.header.frame_id = "tf_frame";
+    cam_info_.height = 480;
+    cam_info_.width  = 640;
+    // No ROI
+    cam_info_.D.resize(5);
+    std::copy(D, D+5, cam_info_.D.begin());
+    std::copy(K, K+9, cam_info_.K.begin());
+    std::copy(R, R+9, cam_info_.R.begin());
+    std::copy(P, P+12, cam_info_.P.begin());
+    cam_info_.distortion_model = sensor_msgs::distortion_models::PLUMB_BOB;
+
+    model_.fromCameraInfo(cam_info_);
+  }
+  
+  sensor_msgs::CameraInfo cam_info_;
+  image_geometry::PinholeCameraModel model_;
+};
+
+TEST_F(PinholeTest, accessorsCorrect)
+{
+  EXPECT_STREQ("tf_frame", model_.tfFrame().c_str());
+  EXPECT_EQ(cam_info_.P[0], model_.fx());
+  EXPECT_EQ(cam_info_.P[5], model_.fy());
+  EXPECT_EQ(cam_info_.P[2], model_.cx());
+  EXPECT_EQ(cam_info_.P[6], model_.cy());
+}
+
+TEST_F(PinholeTest, projectPoint)
+{
+  // Spot test an arbitrary point.
+  {
+    cv::Point2d uv(100, 100);
+    cv::Point3d xyz =  model_.projectPixelTo3dRay(uv);
+    EXPECT_NEAR(-0.62787224048135637, xyz.x, 1e-8);
+    EXPECT_NEAR(-0.41719792045817677, xyz.y, 1e-8);
+    EXPECT_DOUBLE_EQ(1.0, xyz.z);
+  }
+
+  // Principal point should project straight out.
+  {
+    cv::Point2d uv(model_.cx(), model_.cy());
+    cv::Point3d xyz = model_.projectPixelTo3dRay(uv);
+    EXPECT_DOUBLE_EQ(0.0, xyz.x);
+    EXPECT_DOUBLE_EQ(0.0, xyz.y);
+    EXPECT_DOUBLE_EQ(1.0, xyz.z);
+  }
+  
+  // Check projecting to 3d and back over entire image is accurate.
+  const size_t step = 10;
+  for (size_t row = 0; row <= cam_info_.height; row += step) {
+    for (size_t col = 0; col <= cam_info_.width; col += step) {
+      cv::Point2d uv(row, col), uv_back;
+      cv::Point3d xyz = model_.projectPixelTo3dRay(uv);
+      uv_back = model_.project3dToPixel(xyz);
+      // Measured max error at 1.13687e-13
+      EXPECT_NEAR(uv.x, uv_back.x, 1.14e-13) << "at (" << row << ", " << col << ")";
+      EXPECT_NEAR(uv.y, uv_back.y, 1.14e-13) << "at (" << row << ", " << col << ")";
+    }
+  }
+}
+
+TEST_F(PinholeTest, rectifyPoint)
+{
+  // Spot test an arbitrary point.
+  {
+    cv::Point2d uv_raw(100, 100), uv_rect;
+    uv_rect = model_.rectifyPoint(uv_raw);
+    EXPECT_DOUBLE_EQ(142.30311584472656, uv_rect.x);
+    EXPECT_DOUBLE_EQ(132.061065673828, uv_rect.y);
+  }
+
+  /// @todo Need R = identity for the principal point tests.
+#if 0
+  // Test rectifyPoint takes (c'x, c'y) [from K] -> (cx, cy) [from P].
+  double cxp = model_.intrinsicMatrix()(0,2), cyp = model_.intrinsicMatrix()(1,2);
+  {
+    cv::Point2d uv_raw(cxp, cyp), uv_rect;
+    model_.rectifyPoint(uv_raw, uv_rect);
+    EXPECT_NEAR(uv_rect.x, model_.cx(), 1e-4);
+    EXPECT_NEAR(uv_rect.y, model_.cy(), 1e-4);
+  }
+
+  // Test unrectifyPoint takes (cx, cy) [from P] -> (c'x, c'y) [from K].
+  {
+    cv::Point2d uv_rect(model_.cx(), model_.cy()), uv_raw;
+    model_.unrectifyPoint(uv_rect, uv_raw);
+    EXPECT_NEAR(uv_raw.x, cxp, 1e-4);
+    EXPECT_NEAR(uv_raw.y, cyp, 1e-4);
+  }
+#endif
+
+  // Check rectifying then unrectifying over most of the image is accurate.
+  const size_t step = 5;
+  const size_t border = 65; // Expect bad accuracy far from the center of the image.
+  for (size_t row = border; row <= cam_info_.height - border; row += step) {
+    for (size_t col = border; col <= cam_info_.width - border; col += step) {
+      cv::Point2d uv_raw(row, col), uv_rect, uv_unrect;
+      uv_rect = model_.rectifyPoint(uv_raw);
+      uv_unrect = model_.unrectifyPoint(uv_rect);
+      // Check that we're at least within a pixel...
+      EXPECT_NEAR(uv_raw.x, uv_unrect.x, 1.0);
+      EXPECT_NEAR(uv_raw.y, uv_unrect.y, 1.0);
+    }
+  }
+}
+
+TEST_F(PinholeTest, getDeltas)
+{
+  double u = 100.0, v = 200.0, du = 17.0, dv = 23.0, Z = 2.0;
+  cv::Point2d uv0(u, v), uv1(u + du, v + dv);
+  cv::Point3d xyz0, xyz1;
+  xyz0 = model_.projectPixelTo3dRay(uv0);
+  xyz0 *= (Z / xyz0.z);
+  xyz1 = model_.projectPixelTo3dRay(uv1);
+  xyz1 *= (Z / xyz1.z);
+
+  EXPECT_NEAR(model_.getDeltaU(xyz1.x - xyz0.x, Z), du, 1e-4);
+  EXPECT_NEAR(model_.getDeltaV(xyz1.y - xyz0.y, Z), dv, 1e-4);
+  EXPECT_NEAR(model_.getDeltaX(du, Z), xyz1.x - xyz0.x, 1e-4);
+  EXPECT_NEAR(model_.getDeltaY(dv, Z), xyz1.y - xyz0.y, 1e-4);
+}
+
+TEST_F(PinholeTest, initialization)
+{
+
+    sensor_msgs::CameraInfo info;
+    image_geometry::PinholeCameraModel camera;
+
+    camera.fromCameraInfo(info);
+
+    EXPECT_EQ(camera.initialized(), 1);
+    EXPECT_EQ(camera.projectionMatrix().rows, 3);
+    EXPECT_EQ(camera.projectionMatrix().cols, 4);
+}
+
+TEST_F(PinholeTest, rectifyIfCalibrated)
+{
+  /// @todo use forward distortion for a better test
+  // Ideally this test would have two images stored on disk
+  // one which is distorted and the other which is rectified,
+  // and then rectification would take place here and the output
+  // image compared to the one on disk (which would mean if
+  // the distortion coefficients above can't change once paired with
+  // an image).
+
+  // Later could incorporate distort code
+  // (https://github.com/lucasw/vimjay/blob/master/src/standalone/distort_image.cpp)
+  // to take any image distort it, then undistort with rectifyImage,
+  // and given the distortion coefficients are consistent the input image
+  // and final output image should be mostly the same (though some
+  // interpolation error
+  // creeps in), except for outside a masked region where information was lost.
+  // The masked region can be generated with a pure white image that
+  // goes through the same process (if it comes out completely black
+  // then the distortion parameters are problematic).
+
+  // For now generate an image and pass the test simply if
+  // the rectified image does not match the distorted image.
+  // Then zero out the first distortion coefficient and run
+  // the test again.
+  // Then zero out all the distortion coefficients and test
+  // that the output image is the same as the input.
+  cv::Mat distorted_image(cv::Size(cam_info_.width, cam_info_.height), CV_8UC3, cv::Scalar(0, 0, 0));
+
+  // draw a grid
+  const cv::Scalar color = cv::Scalar(255, 255, 255);
+  // draw the lines thick so the proportion of error due to
+  // interpolation is reduced
+  const int thickness = 7;
+  const int type = 8;
+  for (size_t y = 0; y <= cam_info_.height; y += cam_info_.height/10)
+  {
+    cv::line(distorted_image,
+             cv::Point(0, y), cv::Point(cam_info_.width, y),
+             color, type, thickness);
+  }
+  for (size_t x = 0; x <= cam_info_.width; x += cam_info_.width/10)
+  {
+    // draw the lines thick so the prorportion of interpolation error is reduced
+    cv::line(distorted_image,
+             cv::Point(x, 0), cv::Point(x, cam_info_.height),
+             color, type, thickness);
+  }
+
+  cv::Mat rectified_image;
+  // Just making this number up, maybe ought to be larger
+  // since a completely different image would be on the order of
+  // width * height * 255 = 78e6
+  const double diff_threshold = 10000.0;
+  double error;
+
+  // Test that rectified image is sufficiently different
+  // using default distortion
+  model_.rectifyImage(distorted_image, rectified_image);
+  error = cv::norm(distorted_image, rectified_image, cv::NORM_L1);
+  // Just making this number up, maybe ought to be larger
+  EXPECT_GT(error, diff_threshold);
+
+  // Test that rectified image is sufficiently different
+  // using default distortion but with first element zeroed
+  // out.
+  sensor_msgs::CameraInfo cam_info_2 = cam_info_;
+  cam_info_2.D[0] = 0.0;
+  model_.fromCameraInfo(cam_info_2);
+  model_.rectifyImage(distorted_image, rectified_image);
+  error = cv::norm(distorted_image, rectified_image, cv::NORM_L1);
+  EXPECT_GT(error, diff_threshold);
+
+  // Test that rectified image is the same using zero distortion
+  cam_info_2.D.assign(cam_info_2.D.size(), 0);
+  model_.fromCameraInfo(cam_info_2);
+  model_.rectifyImage(distorted_image, rectified_image);
+  error = cv::norm(distorted_image, rectified_image, cv::NORM_L1);
+  EXPECT_EQ(error, 0);
+
+  // Test that rectified image is the same using empty distortion
+  cam_info_2.D.clear();
+  model_.fromCameraInfo(cam_info_2);
+  model_.rectifyImage(distorted_image, rectified_image);
+  error = cv::norm(distorted_image, rectified_image, cv::NORM_L1);
+  EXPECT_EQ(error, 0);
+}
+
+void testUnrectifyImage(const sensor_msgs::CameraInfo& cam_info, const image_geometry::PinholeCameraModel& model)
+{
+  // test for unrectifyImage: call unrectifyImage, call unrectifyPoint in a loop, compare
+
+  // prepare rectified_image
+  cv::Mat rectified_image(model.fullResolution(), CV_8UC3, cv::Scalar(0, 0, 0));
+
+  // draw a grid
+  const cv::Scalar color = cv::Scalar(255, 255, 255);
+  const int thickness = 7;
+  const int type = 8;
+  for (size_t y = 0; y <= rectified_image.rows; y += rectified_image.rows / 10)
+  {
+    cv::line(rectified_image,
+             cv::Point(0, y), cv::Point(cam_info.width, y),
+             color, type, thickness);
+  }
+  for (size_t x = 0; x <= rectified_image.cols; x += rectified_image.cols / 10)
+  {
+    cv::line(rectified_image,
+             cv::Point(x, 0), cv::Point(x, cam_info.height),
+             color, type, thickness);
+  }
+
+  // restrict rectified_image to ROI and resize to new binning
+  rectified_image = rectified_image(model.rawRoi());
+  cv::resize(rectified_image, rectified_image, cv::Size(), 1.0 / model.binningX(), 1.0 / model.binningY(),
+             cv::INTER_NEAREST);
+
+  // unrectify image in one go using unrectifyImage
+  cv::Mat distorted_image;
+  // Just making this number up, maybe ought to be larger
+  // since a completely different image would be on the order of
+  // width * height * 255 = 78e6
+  const double diff_threshold = 10000.0;
+  double error;
+
+  // Test that unrectified image is sufficiently different
+  // using default distortion
+  model.unrectifyImage(rectified_image, distorted_image);
+  error = cv::norm(rectified_image, distorted_image, cv::NORM_L1);
+  // Just making this number up, maybe ought to be larger
+  EXPECT_GT(error, diff_threshold);
+
+  // unrectify image pixel by pixel using unrectifyPoint
+  assert(rectified_image.type() == CV_8UC3);  // need this for at<cv::Vec3b> to be correct
+  cv::Mat distorted_image_by_pixel = cv::Mat::zeros(rectified_image.size(), rectified_image.type());
+  cv::Mat mask = cv::Mat::zeros(rectified_image.size(), CV_8UC1);
+  for (size_t y = 0; y < rectified_image.rows; y++)
+  {
+    for (size_t x = 0; x < rectified_image.cols; x++)
+    {
+      cv::Point2i uv_rect(x, y), uv_raw;
+
+      uv_raw = model.unrectifyPoint(uv_rect);
+
+      if (0 <= uv_raw.x && uv_raw.x < distorted_image_by_pixel.cols && 0 <= uv_raw.y
+          && uv_raw.y < distorted_image_by_pixel.rows)
+      {
+        distorted_image_by_pixel.at<cv::Vec3b>(uv_raw) = rectified_image.at<cv::Vec3b>(uv_rect);
+        mask.at<uchar>(uv_raw) = 255;
+        // Test that both methods produce similar values at the pixels that unrectifyPoint hits; don't test for all
+        // other pixels (the images will differ there, because unrectifyPoint doesn't interpolate missing pixels).
+        // Also don't check for absolute equality, but allow a color difference of up to 200. This still catches
+        // complete misses (color difference would be 255) while allowing for interpolation at the grid borders.
+        EXPECT_LT(distorted_image.at<cv::Vec3b>(uv_raw)[0] - distorted_image_by_pixel.at<cv::Vec3b>(uv_raw)[0], 200);
+      }
+    }
+  }
+
+  // Test that absolute error (due to interpolation) is less than 6% of the maximum possible error
+  error = cv::norm(distorted_image, distorted_image_by_pixel, cv::NORM_L1, mask);
+  EXPECT_LT(error / (distorted_image.size[0] * distorted_image.size[1] * 255), 0.06);
+
+  // Test that unrectifyPoint hits more than 50% of the output image
+  EXPECT_GT((double) cv::countNonZero(mask) / (distorted_image.size[0] * distorted_image.size[1]), 0.5);
+};
+
+TEST_F(PinholeTest, unrectifyImage)
+{
+  testUnrectifyImage(cam_info_, model_);
+}
+
+TEST_F(PinholeTest, unrectifyImageWithBinning)
+{
+  cam_info_.binning_x = 2;
+  cam_info_.binning_y = 2;
+  model_.fromCameraInfo(cam_info_);
+
+  testUnrectifyImage(cam_info_, model_);
+}
+
+TEST_F(PinholeTest, unrectifyImageWithRoi)
+{
+  cam_info_.roi.x_offset = 100;
+  cam_info_.roi.y_offset = 50;
+  cam_info_.roi.width = 400;
+  cam_info_.roi.height = 300;
+  cam_info_.roi.do_rectify = true;
+  model_.fromCameraInfo(cam_info_);
+
+  testUnrectifyImage(cam_info_, model_);
+}
+
+TEST_F(PinholeTest, unrectifyImageWithBinningAndRoi)
+{
+  cam_info_.binning_x = 2;
+  cam_info_.binning_y = 2;
+  cam_info_.roi.x_offset = 100;
+  cam_info_.roi.y_offset = 50;
+  cam_info_.roi.width = 400;
+  cam_info_.roi.height = 300;
+  cam_info_.roi.do_rectify = true;
+  model_.fromCameraInfo(cam_info_);
+
+  testUnrectifyImage(cam_info_, model_);
+}
+
+TEST_F(PinholeTest, rectifiedRoiSize) {
+
+  cv::Rect rectified_roi = model_.rectifiedRoi();
+  cv::Size reduced_resolution = model_.reducedResolution();
+  EXPECT_EQ(0, rectified_roi.x);
+  EXPECT_EQ(0, rectified_roi.y);
+  EXPECT_EQ(640, rectified_roi.width);
+  EXPECT_EQ(480, rectified_roi.height);
+  EXPECT_EQ(640, reduced_resolution.width);
+  EXPECT_EQ(480, reduced_resolution.height);
+
+  cam_info_.binning_x = 2;
+  cam_info_.binning_y = 2;
+  model_.fromCameraInfo(cam_info_);
+  rectified_roi = model_.rectifiedRoi();
+  reduced_resolution = model_.reducedResolution();
+  EXPECT_EQ(0, rectified_roi.x);
+  EXPECT_EQ(0, rectified_roi.y);
+  EXPECT_EQ(640, rectified_roi.width);
+  EXPECT_EQ(480, rectified_roi.height);
+  EXPECT_EQ(320, reduced_resolution.width);
+  EXPECT_EQ(240, reduced_resolution.height);
+
+  cam_info_.binning_x = 1;
+  cam_info_.binning_y = 1;
+  cam_info_.roi.x_offset = 100;
+  cam_info_.roi.y_offset = 50;
+  cam_info_.roi.width = 400;
+  cam_info_.roi.height = 300;
+  cam_info_.roi.do_rectify = true;
+  model_.fromCameraInfo(cam_info_);
+  rectified_roi = model_.rectifiedRoi();
+  reduced_resolution = model_.reducedResolution();
+  EXPECT_EQ(137, rectified_roi.x);
+  EXPECT_EQ(82, rectified_roi.y);
+  EXPECT_EQ(321, rectified_roi.width);
+  EXPECT_EQ(242, rectified_roi.height);
+  EXPECT_EQ(321, reduced_resolution.width);
+  EXPECT_EQ(242, reduced_resolution.height);
+
+  cam_info_.binning_x = 2;
+  cam_info_.binning_y = 2;
+  cam_info_.roi.x_offset = 100;
+  cam_info_.roi.y_offset = 50;
+  cam_info_.roi.width = 400;
+  cam_info_.roi.height = 300;
+  cam_info_.roi.do_rectify = true;
+  model_.fromCameraInfo(cam_info_);
+  rectified_roi = model_.rectifiedRoi();
+  reduced_resolution = model_.reducedResolution();
+  EXPECT_EQ(137, rectified_roi.x);
+  EXPECT_EQ(82, rectified_roi.y);
+  EXPECT_EQ(321, rectified_roi.width);
+  EXPECT_EQ(242, rectified_roi.height);
+  EXPECT_EQ(160, reduced_resolution.width);
+  EXPECT_EQ(121, reduced_resolution.height);
+}
+
+TEST_F(PinholeTest, rectifiedRoiCaching)
+{
+  // Test that the following sequence works correctly:
+  // 1. fromCameraInfo is called with ROI A.  | rectified_roi_dirty = true
+  // (already happened in SetUp())
+
+  // 2. rectifiedRoi is called                | rectified_roi_dirty = false
+  cv::Rect actual_roi_a = model_.rectifiedRoi();
+  cv::Rect expected_roi_a(0, 0, 640, 480);
+  EXPECT_EQ(expected_roi_a, actual_roi_a);
+
+  // 3. fromCameraInfo is called with ROI B.  | rectified_roi_dirty = true
+  cam_info_.roi.x_offset = 100;
+  cam_info_.roi.y_offset = 50;
+  cam_info_.roi.width = 400;
+  cam_info_.roi.height = 300;
+  cam_info_.roi.do_rectify = true;
+  model_.fromCameraInfo(cam_info_);
+
+  // 4. fromCameraInfo is called again with ROI B.  | rectified_roi_dirty should still be true!
+  model_.fromCameraInfo(cam_info_);
+
+  // 5. rectifiedRoi is called
+  // There was a bug before where rectified_roi_dirty was incorrectly set to `false` by step 4.
+  // If rectifiedRoi was called again, the cached rectified_roi for
+  // ROI A was returned, but it should be recalculated based on ROI B.
+  // This test checks that this behavior is correct.
+  cv::Rect actual_roi_b = model_.rectifiedRoi();
+  cv::Rect expected_roi_b(137, 82, 321, 242);
+  EXPECT_EQ(expected_roi_b, actual_roi_b);
+}
+
+int main(int argc, char** argv)
+{
+  testing::InitGoogleTest(&argc, argv);
+  return RUN_ALL_TESTS();
+}
--- /dev/null
+++ ros-noetic-image-geometry-1.16.2/test/utest_equi.cpp
@@ -0,0 +1,257 @@
+#include "image_geometry/pinhole_camera_model.h"
+#include <sensor_msgs/distortion_models.h>
+#include <gtest/gtest.h>
+
+/// @todo Tests with simple values (R = identity, D = 0, P = K or simple scaling)
+/// @todo Test projection functions for right stereo values, P(:,3) != 0
+/// @todo Tests for [un]rectifyImage
+/// @todo Tests using ROI, needs support from PinholeCameraModel
+/// @todo Tests for StereoCameraModel
+
+class EquidistantTest : public testing::Test
+{
+protected:
+  virtual void SetUp()
+  {
+    /// @todo Just load these from file
+    // These parameters are taken from a real camera calibration
+    double D[] = {-0.08857683871674071, 0.0708113094372378, -0.09127623055964429, 0.04006922269778478};
+    double K[] = {403.603063319358,               0.0, 306.15842863283063,
+                               0.0, 403.7028851121003, 261.09715697592696,
+                               0.0,               0.0,                1.0};
+    double R[] = {0.999963944103842, -0.008484152966323483, 0.00036005656766869323,
+                  0.008484153516269438, 0.9999640089218772, 0.0,
+                  -0.0003600436088446379, 3.0547751946422504e-06, 0.999999935179632};
+    double P[] = {347.2569964503485, 0.0, 350.5, 0.0,
+                  0.0, 347.2569964503485, 256.0, 0.0,
+                  0.0, 0.0, 1.0, 0.0};
+
+    cam_info_.header.frame_id = "tf_frame";
+    cam_info_.height = 512;
+    cam_info_.width  = 640;
+    // No ROI
+    cam_info_.D.resize(4);
+    std::copy(D, D+4, cam_info_.D.begin());
+    std::copy(K, K+9, cam_info_.K.begin());
+    std::copy(R, R+9, cam_info_.R.begin());
+    std::copy(P, P+12, cam_info_.P.begin());
+    cam_info_.distortion_model = sensor_msgs::distortion_models::EQUIDISTANT;
+
+    model_.fromCameraInfo(cam_info_);
+  }
+
+  sensor_msgs::CameraInfo cam_info_;
+  image_geometry::PinholeCameraModel model_;
+};
+
+TEST_F(EquidistantTest, accessorsCorrect)
+{
+  EXPECT_STREQ("tf_frame", model_.tfFrame().c_str());
+  EXPECT_EQ(cam_info_.P[0], model_.fx());
+  EXPECT_EQ(cam_info_.P[5], model_.fy());
+  EXPECT_EQ(cam_info_.P[2], model_.cx());
+  EXPECT_EQ(cam_info_.P[6], model_.cy());
+}
+
+TEST_F(EquidistantTest, projectPoint)
+{
+  // Spot test an arbitrary point.
+  {
+    cv::Point2d uv(100, 100);
+    cv::Point3d xyz =  model_.projectPixelTo3dRay(uv);
+    EXPECT_NEAR(-0.72136775518018115, xyz.x, 1e-8);
+    EXPECT_NEAR(-0.449235009214005, xyz.y, 1e-8);
+    EXPECT_DOUBLE_EQ(1.0, xyz.z);
+  }
+
+  // Principal point should project straight out.
+  {
+    cv::Point2d uv(model_.cx(), model_.cy());
+    cv::Point3d xyz = model_.projectPixelTo3dRay(uv);
+    EXPECT_DOUBLE_EQ(0.0, xyz.x);
+    EXPECT_DOUBLE_EQ(0.0, xyz.y);
+    EXPECT_DOUBLE_EQ(1.0, xyz.z);
+  }
+
+  // Check projecting to 3d and back over entire image is accurate.
+  const size_t step = 10;
+  for (size_t row = 0; row <= cam_info_.height; row += step) {
+    for (size_t col = 0; col <= cam_info_.width; col += step) {
+      cv::Point2d uv(row, col), uv_back;
+      cv::Point3d xyz = model_.projectPixelTo3dRay(uv);
+      uv_back = model_.project3dToPixel(xyz);
+      // Measured max error at 1.13687e-13
+      EXPECT_NEAR(uv.x, uv_back.x, 1.14e-13) << "at (" << row << ", " << col << ")";
+      EXPECT_NEAR(uv.y, uv_back.y, 1.14e-13) << "at (" << row << ", " << col << ")";
+    }
+  }
+}
+
+TEST_F(EquidistantTest, rectifyPoint)
+{
+  // Spot test an arbitrary point.
+  {
+    cv::Point2d uv_raw(100, 100), uv_rect;
+    uv_rect = model_.rectifyPoint(uv_raw);
+    EXPECT_DOUBLE_EQ(135.45747375488281, uv_rect.x);
+    EXPECT_DOUBLE_EQ(84.945091247558594, uv_rect.y);
+  }
+
+  /// @todo Need R = identity for the principal point tests.
+#if 0
+  // Test rectifyPoint takes (c'x, c'y) [from K] -> (cx, cy) [from P].
+  double cxp = model_.intrinsicMatrix()(0,2), cyp = model_.intrinsicMatrix()(1,2);
+  {
+    cv::Point2d uv_raw(cxp, cyp), uv_rect;
+    model_.rectifyPoint(uv_raw, uv_rect);
+    EXPECT_NEAR(uv_rect.x, model_.cx(), 1e-4);
+    EXPECT_NEAR(uv_rect.y, model_.cy(), 1e-4);
+  }
+
+  // Test unrectifyPoint takes (cx, cy) [from P] -> (c'x, c'y) [from K].
+  {
+    cv::Point2d uv_rect(model_.cx(), model_.cy()), uv_raw;
+    model_.unrectifyPoint(uv_rect, uv_raw);
+    EXPECT_NEAR(uv_raw.x, cxp, 1e-4);
+    EXPECT_NEAR(uv_raw.y, cyp, 1e-4);
+  }
+#endif
+
+  // Check rectifying then unrectifying is accurate.
+  const size_t step = 5;
+  for (size_t row = 0; row <= cam_info_.height; row += step) {
+    for (size_t col = 0; col <= cam_info_.width; col += step) {
+      cv::Point2d uv_raw(row, col), uv_rect, uv_unrect;
+      uv_rect = model_.rectifyPoint(uv_raw);
+      uv_unrect = model_.unrectifyPoint(uv_rect);
+      EXPECT_NEAR(uv_raw.x, uv_unrect.x, 0.01);
+      EXPECT_NEAR(uv_raw.y, uv_unrect.y, 0.01);
+    }
+  }
+}
+
+TEST_F(EquidistantTest, getDeltas)
+{
+  double u = 100.0, v = 200.0, du = 17.0, dv = 23.0, Z = 2.0;
+  cv::Point2d uv0(u, v), uv1(u + du, v + dv);
+  cv::Point3d xyz0, xyz1;
+  xyz0 = model_.projectPixelTo3dRay(uv0);
+  xyz0 *= (Z / xyz0.z);
+  xyz1 = model_.projectPixelTo3dRay(uv1);
+  xyz1 *= (Z / xyz1.z);
+
+  EXPECT_NEAR(model_.getDeltaU(xyz1.x - xyz0.x, Z), du, 1e-4);
+  EXPECT_NEAR(model_.getDeltaV(xyz1.y - xyz0.y, Z), dv, 1e-4);
+  EXPECT_NEAR(model_.getDeltaX(du, Z), xyz1.x - xyz0.x, 1e-4);
+  EXPECT_NEAR(model_.getDeltaY(dv, Z), xyz1.y - xyz0.y, 1e-4);
+}
+
+TEST_F(EquidistantTest, initialization)
+{
+
+    sensor_msgs::CameraInfo info;
+    image_geometry::PinholeCameraModel camera;
+
+    camera.fromCameraInfo(info);
+
+    EXPECT_EQ(camera.initialized(), 1);
+    EXPECT_EQ(camera.projectionMatrix().rows, 3);
+    EXPECT_EQ(camera.projectionMatrix().cols, 4);
+}
+
+TEST_F(EquidistantTest, rectifyIfCalibrated)
+{
+  /// @todo use forward distortion for a better test
+  // Ideally this test would have two images stored on disk
+  // one which is distorted and the other which is rectified,
+  // and then rectification would take place here and the output
+  // image compared to the one on disk (which would mean if
+  // the distortion coefficients above can't change once paired with
+  // an image).
+
+  // Later could incorporate distort code
+  // (https://github.com/lucasw/vimjay/blob/master/src/standalone/distort_image.cpp)
+  // to take any image distort it, then undistort with rectifyImage,
+  // and given the distortion coefficients are consistent the input image
+  // and final output image should be mostly the same (though some
+  // interpolation error
+  // creeps in), except for outside a masked region where information was lost.
+  // The masked region can be generated with a pure white image that
+  // goes through the same process (if it comes out completely black
+  // then the distortion parameters are problematic).
+
+  // For now generate an image and pass the test simply if
+  // the rectified image does not match the distorted image.
+  // Then zero out the first distortion coefficient and run
+  // the test again.
+  // Then zero out all the distortion coefficients and test
+  // that the output image is the same as the input.
+  cv::Mat distorted_image(cv::Size(cam_info_.width, cam_info_.height), CV_8UC3, cv::Scalar(0, 0, 0));
+
+  // draw a grid
+  const cv::Scalar color = cv::Scalar(255, 255, 255);
+  // draw the lines thick so the proportion of error due to
+  // interpolation is reduced
+  const int thickness = 7;
+  const int type = 8;
+  for (size_t y = 0; y <= cam_info_.height; y += cam_info_.height/10)
+  {
+    cv::line(distorted_image,
+             cv::Point(0, y), cv::Point(cam_info_.width, y),
+             color, type, thickness);
+  }
+  for (size_t x = 0; x <= cam_info_.width; x += cam_info_.width/10)
+  {
+    // draw the lines thick so the prorportion of interpolation error is reduced
+    cv::line(distorted_image,
+             cv::Point(x, 0), cv::Point(x, cam_info_.height),
+             color, type, thickness);
+  }
+
+  cv::Mat rectified_image;
+  // Just making this number up, maybe ought to be larger
+  // since a completely different image would be on the order of
+  // width * height * 255 = 78e6
+  const double diff_threshold = 10000.0;
+  double error;
+
+  // Test that rectified image is sufficiently different
+  // using default distortion
+  model_.rectifyImage(distorted_image, rectified_image);
+  error = cv::norm(distorted_image, rectified_image, cv::NORM_L1);
+  // Just making this number up, maybe ought to be larger
+  EXPECT_GT(error, diff_threshold);
+
+  // Test that rectified image is sufficiently different
+  // using default distortion but with first element zeroed
+  // out.
+  sensor_msgs::CameraInfo cam_info_2 = cam_info_;
+  cam_info_2.D[0] = 0.0;
+  model_.fromCameraInfo(cam_info_2);
+  model_.rectifyImage(distorted_image, rectified_image);
+  error = cv::norm(distorted_image, rectified_image, cv::NORM_L1);
+  EXPECT_GT(error, diff_threshold);
+
+  // Test that rectified image is the same using zero distortion
+  cam_info_2.D.assign(cam_info_2.D.size(), 0);
+  model_.fromCameraInfo(cam_info_2);
+  model_.rectifyImage(distorted_image, rectified_image);
+  error = cv::norm(distorted_image, rectified_image, cv::NORM_L1);
+  EXPECT_EQ(error, 0);
+
+  // Test that rectified image is the same using empty distortion
+  cam_info_2.D.clear();
+  model_.fromCameraInfo(cam_info_2);
+  model_.rectifyImage(distorted_image, rectified_image);
+  error = cv::norm(distorted_image, rectified_image, cv::NORM_L1);
+  EXPECT_EQ(error, 0);
+
+  // restore original distortion
+  model_.fromCameraInfo(cam_info_);
+}
+
+int main(int argc, char** argv)
+{
+  testing::InitGoogleTest(&argc, argv);
+  return RUN_ALL_TESTS();
+}
